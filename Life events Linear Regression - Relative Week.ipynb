{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 996,
   "id": "f4edb049",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (0.12.2)\n",
      "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (0.5.1)\n",
      "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.1.5)\n",
      "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->statsmodels) (2021.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5->statsmodels) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: vaderSentiment in /home/sagarwal420/.local/lib/python3.6/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vaderSentiment) (2.26.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->vaderSentiment) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->vaderSentiment) (2018.1.18)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->vaderSentiment) (1.22)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (6.0.7)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert) (4.8.1)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.5.4)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (4.3.3)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert) (4.1.0)\n",
      "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (3.0.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.8.4)\n",
      "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (5.1.3)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (2.10.0)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.5.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (1.5.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert) (2.0.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.5 in /usr/local/lib/python3.6/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert) (7.0.3)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.6/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert) (1.5.1)\n",
      "Requirement already satisfied: async-generator in /usr/local/lib/python3.6/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert) (1.10)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert) (2.8.2)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert) (22.3.0)\n",
      "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert) (6.1)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert) (3.2.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (4.8.1)\n",
      "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (1.15.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/lib/python3/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (17.4.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (58.1.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert) (5.1.0)\n",
      "Requirement already satisfied: webencodings in /usr/lib/python3/dist-packages (from bleach->nbconvert) (0.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert) (21.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert) (2.4.7)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tabulate in /home/sagarwal420/.local/lib/python3.6/site-packages (0.8.10)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.19.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (6.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from nltk) (1.0.1)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.10.31-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (756 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 756 kB 13.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 6.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.6/dist-packages (from tqdm->nltk) (5.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from importlib-resources->tqdm->nltk) (3.5.0)\n",
      "Installing collected packages: tqdm, regex, nltk\n",
      "Successfully installed nltk-3.6.7 regex-2022.10.31 tqdm-4.64.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install statsmodels\n",
    "!pip3 install vaderSentiment\n",
    "!pip3 install nbconvert\n",
    "!pip3 install tabulate\n",
    "!pip3 install --upgrade scipy\n",
    "!pip3 install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bc4ee099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "from statistics import mean\n",
    "\n",
    "from datetime import date, timedelta\n",
    "import datetime\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.gof import chisquare as chisquare\n",
    "import vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.tools.tools import pinv_extended\n",
    "\n",
    "import csv\n",
    "from patsy import ModelDesc\n",
    "from tabulate import tabulate\n",
    "\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "b39d1d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.datetime.strptime(\"2020-08-22\", \"%Y-%m-%d\").date()\n",
    "\n",
    "def update_end_date(row, columnName, latestDate):\n",
    "    if row[columnName] == row[columnName]:\n",
    "        return row[columnName]\n",
    "    else:\n",
    "        return latestDate\n",
    "\n",
    "def getDays(row, beginColumnName, endColumnName):\n",
    "    return (row[endColumnName] - row[beginColumnName]).days\n",
    "\n",
    "def calculate_recency(row, columnName):\n",
    "    return (current_date - row[columnName]).days\n",
    "\n",
    "def lookup_index(row, columnName, array):\n",
    "    if(row[columnName] not in array):\n",
    "        return -1\n",
    "    return array.index(row[columnName]) + 1\n",
    "\n",
    "def fix_signficance(row):\n",
    "    if('significance' in row['valence']):\n",
    "        return row['valence']\n",
    "    else:\n",
    "        return row['significance']\n",
    "\n",
    "def fix_valence(row):\n",
    "    if('significance' in row['significance']):\n",
    "        return row['valence']\n",
    "    else:\n",
    "        return row['significance']  \n",
    "\n",
    "def compute_sentiment(row):\n",
    "    post = row['Text']\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    vs = analyzer.polarity_scores(post)\n",
    "    sentiment = 0\n",
    "    if (vs[\"neu\"]>0.8):\n",
    "        sentiment = 0\n",
    "    elif (vs[\"pos\"]==vs[\"neg\"]):\n",
    "        sentiment = 0\n",
    "    elif (vs[\"pos\"]>vs[\"neg\"]):\n",
    "        sentiment = 1\n",
    "    elif (vs[\"neg\"]>vs[\"neu\"]):\n",
    "        sentiment = -1\n",
    "    return sentiment\n",
    "\n",
    "def convert_valence_to_sentiment(row):\n",
    "    valence = row['valence']\n",
    "    retVal = 0\n",
    "    if (valence == 'Neither Positive or Negative'):\n",
    "        retVal = 0\n",
    "    elif(\"Positive\" in valence):\n",
    "        retVal = 1\n",
    "    elif(\"Negative\" in valence):\n",
    "        retVal = -1\n",
    "    return retVal\n",
    "\n",
    "def update_status(row, columnName):\n",
    "    if row[columnName] == row[columnName]:\n",
    "        if \"ongoing\" in row[columnName].lower():\n",
    "            return \"Ongoing\"\n",
    "        return row[columnName]\n",
    "    else:\n",
    "        return \"Ended\"\n",
    "\n",
    "def update_education_level(row, columnName):\n",
    "    if 'college' in row[columnName].lower():\n",
    "        return \"College\"\n",
    "    elif 'doctoral' in row[columnName].lower():\n",
    "        return \"Doctoral\"\n",
    "    elif 'master' in row[columnName].lower() or 'grad' in row[columnName].lower():\n",
    "        return \"Graduate\"\n",
    "    elif 'hs' in row[columnName].lower() or 'high school' in row[columnName].lower():\n",
    "        return \"High\"\n",
    "    \n",
    "    return row[columnName]\n",
    "\n",
    "def normalize(series):\n",
    "    return (series - series.mean())/series.std()\n",
    "\n",
    "def star_pvals(p_val):\n",
    "    if p_val<0.001:\n",
    "        return \"***\"\n",
    "    elif p_val<0.01:\n",
    "        return \"**\"\n",
    "    elif p_val<0.05:\n",
    "        return \"*\"\n",
    "    return \".\"\n",
    "\n",
    "def no_star_pvals(p_val):\n",
    "    if p_val<0.001:\n",
    "        return 3\n",
    "    elif p_val<0.01:\n",
    "        return 2\n",
    "    elif p_val<0.05:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4331d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_variables             = 'shipley_vocab + shipley_abs + openness + conscientiousness + extraversion + agreeableness + neuroticism + pos_affect + neg_affect + stai_trait + education_level + psqi + age + gender'\n",
    "combined_control_variables    = 'shipley_vocab + shipley_abs + openness + conscientiousness + extraversion + agreeableness + neuroticism + pos_affect + neg_affect + stai_trait + education_level + psqi + age + gender + data_type'\n",
    "\n",
    "sr_life_event_variables       = 'Anticipation_sr + LifeEventType_sr + valence_sr + recency_sr + status_sr + Intimacy_sr + Scope_sr + significance_sr'\n",
    "sm_life_event_variables       = 'Anticipation_sm + LifeEventType_sm + valence_sm + recency_sm + status_sm + Intimacy_sm + Scope_sm + significance_sm'\n",
    "combined_life_event_variables = 'Anticipation + LifeEventFamily + valence + recency + status + Intimacy + Scope + data_type'\n",
    "\n",
    "sr_all_variables     = 'shipley_vocab + shipley_abs + openness + conscientiousness + extraversion + agreeableness + neuroticism + pos_affect + neg_affect + stai_trait + education_level + psqi + age + gender + Anticipation + LifeEventFamily + valence + recency + status + Intimacy + Scope + significance_label'\n",
    "sm_all_variables     = 'shipley_vocab + shipley_abs + openness + conscientiousness + extraversion + agreeableness + neuroticism + pos_affect + neg_affect + stai_trait + education_level + psqi + age + gender + Anticipation + LifeEventFamily + valence + recency + status + Intimacy + Scope'\n",
    "combined_all_variables        = 'shipley_vocab + shipley_abs + openness + conscientiousness + extraversion + agreeableness + neuroticism + pos_affect + neg_affect + stai_trait + education_level + psqi + age + gender + Anticipation + LifeEventFamily + valence + recency + status + Intimacy + Scope + data_type'\n",
    "# combined_sm_sr_all_variables  = 'shipley_vocab_sm + shipley_vocab_sr + shipley_abs_sm + shipley_abs_sr + openness_sm + openness_sr + conscientiousness_sm + conscientiousness_sr + extraversion_sm + extraversion_sr + agreeableness_sm + agreeableness_sr + neuroticism_sm + neuroticism_sr + pos_affect_sm + pos_affect_sr + neg_affect_sm + neg_affect_sr + stai_trait_sm + stai_trait_sr + education_level_sm + education_level_sr + psqi_sm + psqi_sr + age_sm + age_sr + gender_sm + gender_sr + Anticipation_sm + Anticipation_sr + LifeEventFamily_sm + LifeEventFamily_sr + valence_sm + valence_sr + Intimacy_sm + Intimacy_sr + Scope_sm + Scope_sr + data_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcc9ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_demographics_data():\n",
    "    demographics_data = pd.read_csv('data/igtbs_demographics_complete.csv', parse_dates=True)\n",
    "    demographics_data = demographics_data[['age','gender','snapshot_id', 'shipley.vocab', 'shipley.abs', 'openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism','pos.affect','neg.affect','stai.trait','psqi','educ']]\n",
    "    demographics_data['education_level'] = demographics_data.apply(update_education_level, columnName='educ', axis=1)\n",
    "    demographics_data = demographics_data.drop(columns=['educ'])\n",
    "    demographics_data = demographics_data.rename(columns={\n",
    "        'shipley.vocab': 'shipley_vocab',\n",
    "        'shipley.abs': 'shipley_abs',\n",
    "        'pos.affect': 'pos_affect',\n",
    "        'neg.affect': 'neg_affect',\n",
    "        'stai.trait': 'stai_trait'\n",
    "    })\n",
    "    demographics_data = demographics_data.dropna()\n",
    "    return demographics_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8ae65d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_survey_categories():\n",
    "    df_self_reported_categories = pd.read_csv('data/Life Events Categories Mapping - Self-Reported Categories.csv')\n",
    "    return df_self_reported_categories\n",
    "\n",
    "def load_survey_data_without_categories():\n",
    "    df_survey = pd.read_csv('data/Superimposed/LifeEvents_Curated_non_blinded.csv', parse_dates=True)    \n",
    "    df_survey = df_survey[['snapshot_id', 'description','UpdatedBeginDate', 'UpdatedEndDate','life_event_type', 'work_perf_impact', 'significance','valence', 'ended_or_ongoing']]\n",
    "\n",
    "    # Date manipulation\n",
    "    latest_date = max(datetime.datetime.strptime(str(x), \"%Y-%m-%d\").date() if x == x else datetime.date.min for x in df_survey['UpdatedEndDate'])\n",
    "    latest_date = max(latest_date, max(datetime.datetime.strptime(str(x), \"%Y-%m-%d\").date() if x == x else datetime.date.min for x in df_survey['UpdatedBeginDate']))\n",
    "    df_survey = df_survey.drop(df_survey[df_survey['UpdatedBeginDate'].isnull() == True].index)\n",
    "\n",
    "    df_survey['UpdatedBeginDate'] = pd.to_datetime(df_survey['UpdatedBeginDate'], format = '%Y-%m-%d').dt.date\n",
    "    df_survey['UpdatedEndDate'] = df_survey.apply(update_end_date, columnName='UpdatedEndDate', latestDate=latest_date, axis=1)\n",
    "    df_survey['UpdatedEndDate'] = pd.to_datetime(df_survey['UpdatedEndDate'], format = '%Y-%m-%d').dt.date\n",
    "\n",
    "    df_survey['num_of_days'] = df_survey.apply(getDays, endColumnName='UpdatedEndDate', beginColumnName='UpdatedBeginDate', axis=1)\n",
    "    df_survey['recency'] = df_survey.apply(calculate_recency, columnName='UpdatedEndDate', axis=1)\n",
    "\n",
    "    # Update values for valence and significance\n",
    "    df_survey.replace({'valence': {np.nan: 'Neither Positive or Negative'}, 'significance': {np.nan: 'Neither Positive or Negative'}}, inplace=True)\n",
    "    df_survey['fixed_signficance'] = df_survey.apply(fix_signficance, axis = 1)\n",
    "    df_survey['fixed_valence'] = df_survey.apply(fix_valence, axis = 1)\n",
    "    df_survey = df_survey.drop(columns = ['valence', 'significance'])\n",
    "    df_survey = df_survey.rename(columns={\"fixed_signficance\": \"significance\", \"fixed_valence\": \"valence\"})\n",
    "    df_survey['valence'] = df_survey.apply(convert_valence_to_sentiment, axis=1)\n",
    "    df_survey['ended_or_ongoing'] = df_survey.apply(update_status, columnName='ended_or_ongoing', axis=1)\n",
    "\n",
    "    # Select columns we are interested in\n",
    "    df_survey = df_survey[['snapshot_id', 'description', 'UpdatedBeginDate', 'UpdatedEndDate', 'significance', 'valence', 'ended_or_ongoing', 'recency']]\n",
    "\n",
    "    # Label encoding for significance\n",
    "    le_significance = LabelEncoder()\n",
    "    le_significance.fit(df_survey['significance'].values)\n",
    "    df_survey['significance_label'] = df_survey.apply(lambda x: le_significance.transform([x['significance']])[0], axis=1)\n",
    "    df_survey = df_survey.drop(columns=['significance'])\n",
    "\n",
    "    return df_survey\n",
    "\n",
    "def load_survey_data():\n",
    "    df_survey_without_categories = load_survey_data_without_categories()\n",
    "    df_self_reported_categories = load_survey_categories()\n",
    "    df_survey = pd.merge(df_survey_without_categories, df_self_reported_categories, how=\"inner\", left_on=\"description\", right_on=\"SR_LifeEvent\")\n",
    "    df_survey = df_survey.drop(columns=['description', 'SR_LifeEvent', 'LifeEventFinal', 'LifeEventFamily2'])\n",
    "    df_survey['significance_label'] = (df_survey['significance_label'] - df_survey['significance_label'].min()) / (df_survey['significance_label'].max() - df_survey['significance_label'].min())    \n",
    "    df_survey = df_survey.rename(columns={'ended_or_ongoing':'status', 'LifeEventFamily': 'LifeEventType', 'significance_label': 'significance'})\n",
    "\n",
    "\n",
    "    return df_survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80470e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = load_social_media_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f94bbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     1422\n",
       "2      160\n",
       "3       48\n",
       "4       12\n",
       "5        6\n",
       "10       1\n",
       "6        1\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = sm.groupby(['snapshot_id', 'created_date']).count().reset_index()\n",
    "s['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "480efef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_social_media_categories():\n",
    "    df_social_media_categories = pd.read_csv('data/Life Events Categories Mapping - Social Media Categories-2.csv')\n",
    "    df_social_media_categories['SignificanceRank'] = df_social_media_categories['SignificanceRank'].fillna(df_social_media_categories['SignificanceRank'].max())\n",
    "    return df_social_media_categories\n",
    "\n",
    "def load_social_media_data_without_categories():\n",
    "    df_social_media_data = pd.read_csv('data/Superimposed/Facebook Data For Life Events-Combined - FB Data.csv')\n",
    "    df_social_media_data = df_social_media_data[['snapshot_id', 'created_time', 'Text', 'final_life_event_category_2', 'ended/ongoing']]\n",
    "    df_social_media_data = df_social_media_data.replace({'PostiveMove':'PositiveMove', 'Negative Move':'NegativeMove'})\n",
    "    df_social_media_data = df_social_media_data.drop(df_social_media_data[((df_social_media_data['final_life_event_category_2'].isnull() == True))].index)\n",
    "    df_social_media_data['created_date'] = pd.to_datetime(df_social_media_data['created_time'], format = '%Y-%m-%d %H:%M:%S').dt.date\n",
    "    df_social_media_data['valence'] = df_social_media_data.apply(compute_sentiment, axis=1)\n",
    "    df_social_media_data = df_social_media_data.drop(columns=['created_time','Text'])\n",
    "    df_social_media_data['recency'] = df_social_media_data.apply(calculate_recency, columnName='created_date', axis=1)\n",
    "    df_social_media_data['ended/ongoing'] = df_social_media_data.apply(update_status, columnName='ended/ongoing', axis=1)\n",
    "    return df_social_media_data\n",
    "\n",
    "def load_social_media_data():\n",
    "    df_social_media_data = load_social_media_data_without_categories()\n",
    "    df_social_media_categories = load_social_media_categories()\n",
    "    df_social_media_data_with_categories = pd.merge(df_social_media_data, df_social_media_categories, how=\"inner\", left_on='final_life_event_category_2', right_on='SM_LifeEvent')\n",
    "    df_social_media_data_with_categories = df_social_media_data_with_categories.drop(columns=['final_life_event_category_2','SM_LifeEvent','LifeEventFamily2','Comments'])\n",
    "    df_social_media_data_with_categories = df_social_media_data_with_categories.rename(columns={'ended/ongoing':'status', 'LifeEventFamily': 'LifeEventType', 'SignificanceRank': 'significance'})\n",
    "    df_social_media_data_with_categories['significance'].fillna(df_social_media_data_with_categories['significance'].max())\n",
    "    df_social_media_data_with_categories['significance'] = (df_social_media_data_with_categories['significance'] - df_social_media_data_with_categories['significance'].min()) / (df_social_media_data_with_categories['significance'].max() - df_social_media_data_with_categories['significance'].min())    \n",
    "    \n",
    "    return df_social_media_data_with_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6108bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dailies_data():\n",
    "    df_dailies = pd.read_csv('data/Superimposed/dailies_scores.csv', low_memory=False)\n",
    "    df_dailies = df_dailies[['snapshot_id','day', 'alc_status', 'alc.quantity.d', 'anxiety.d', 'pos.affect.d', 'neg.affect.d','sleep.d', 'stress.d']]\n",
    "    df_dailies['day'] = pd.to_datetime(df_dailies['day'], format='%Y-%m-%d').dt.date\n",
    "    df_dailies = df_dailies.rename(columns={'alc.quantity.d': 'alc_quantity',\n",
    "    'anxiety.d': 'anxiety',\n",
    "    'pos.affect.d': 'pos_affect',\n",
    "    'neg.affect.d': 'neg_affect',\n",
    "    'sleep.d': 'sleep',\n",
    "    'stress.d': 'stress'})\n",
    "    df_dailies['sleep'] = df_dailies['sleep'] + 1\n",
    "    return df_dailies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3224acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_year(row, columnName):\n",
    "    return row[columnName].isocalendar()[0]\n",
    "\n",
    "def calculate_week(row, columnName):\n",
    "    return row[columnName].isocalendar()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d890896e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snapshot_id</th>\n",
       "      <th>status</th>\n",
       "      <th>created_date</th>\n",
       "      <th>valence</th>\n",
       "      <th>recency</th>\n",
       "      <th>LifeEventType</th>\n",
       "      <th>Anticipation</th>\n",
       "      <th>Intimacy</th>\n",
       "      <th>Scope</th>\n",
       "      <th>significance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12840161237957324034</td>\n",
       "      <td>Ongoing</td>\n",
       "      <td>2018-03-16</td>\n",
       "      <td>0</td>\n",
       "      <td>890</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Anticipated</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.794118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11156103277197680506</td>\n",
       "      <td>Ongoing</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>753</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Anticipated</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.794118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11329586216091316598</td>\n",
       "      <td>Ongoing</td>\n",
       "      <td>2018-09-08</td>\n",
       "      <td>0</td>\n",
       "      <td>714</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Anticipated</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.794118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13543308681200334026</td>\n",
       "      <td>Ongoing</td>\n",
       "      <td>2018-07-22</td>\n",
       "      <td>0</td>\n",
       "      <td>762</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Anticipated</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.794118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12676581714475000627</td>\n",
       "      <td>Ongoing</td>\n",
       "      <td>2018-04-25</td>\n",
       "      <td>0</td>\n",
       "      <td>850</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Anticipated</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.794118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>10729524556661174446</td>\n",
       "      <td>Ongoing</td>\n",
       "      <td>2018-12-19</td>\n",
       "      <td>0</td>\n",
       "      <td>612</td>\n",
       "      <td>School</td>\n",
       "      <td>Unanticipated</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>9767765376628075157</td>\n",
       "      <td>Ongoing</td>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>0</td>\n",
       "      <td>757</td>\n",
       "      <td>Health</td>\n",
       "      <td>Anticipated</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.465686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>9767765376628075157</td>\n",
       "      <td>Ongoing</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>0</td>\n",
       "      <td>669</td>\n",
       "      <td>Health</td>\n",
       "      <td>Anticipated</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.465686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>9767765376628075157</td>\n",
       "      <td>ended</td>\n",
       "      <td>2018-09-19</td>\n",
       "      <td>1</td>\n",
       "      <td>703</td>\n",
       "      <td>Health</td>\n",
       "      <td>Unanticipated</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>13491403714608340181</td>\n",
       "      <td>Ongoing</td>\n",
       "      <td>2018-11-23</td>\n",
       "      <td>0</td>\n",
       "      <td>638</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Anticipated</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.794118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1980 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               snapshot_id   status created_date  valence  recency  \\\n",
       "0     12840161237957324034  Ongoing   2018-03-16        0      890   \n",
       "1     11156103277197680506  Ongoing   2018-07-31        1      753   \n",
       "2     11329586216091316598  Ongoing   2018-09-08        0      714   \n",
       "3     13543308681200334026  Ongoing   2018-07-22        0      762   \n",
       "4     12676581714475000627  Ongoing   2018-04-25        0      850   \n",
       "...                    ...      ...          ...      ...      ...   \n",
       "1975  10729524556661174446  Ongoing   2018-12-19        0      612   \n",
       "1976   9767765376628075157  Ongoing   2018-07-27        0      757   \n",
       "1977   9767765376628075157  Ongoing   2018-10-23        0      669   \n",
       "1978   9767765376628075157    ended   2018-09-19        1      703   \n",
       "1979  13491403714608340181  Ongoing   2018-11-23        0      638   \n",
       "\n",
       "     LifeEventType   Anticipation  Intimacy  Scope  significance  \n",
       "0         Personal    Anticipated         2      2      0.794118  \n",
       "1         Personal    Anticipated         2      2      0.794118  \n",
       "2         Personal    Anticipated         2      2      0.794118  \n",
       "3         Personal    Anticipated         2      2      0.794118  \n",
       "4         Personal    Anticipated         2      2      0.794118  \n",
       "...            ...            ...       ...    ...           ...  \n",
       "1975        School  Unanticipated         3      2      0.833333  \n",
       "1976        Health    Anticipated         3      3      0.465686  \n",
       "1977        Health    Anticipated         3      3      0.465686  \n",
       "1978        Health  Unanticipated         3      3      0.176471  \n",
       "1979      Personal    Anticipated         2      2      0.794118  \n",
       "\n",
       "[1980 rows x 10 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_social_media_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "383262e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekly_avg(row, data):\n",
    "    days_3 = timedelta(days=3)\n",
    "    days_1 = timedelta(days=1)\n",
    "    before = row['day'] - days_3\n",
    "    after = row['day'] + days_3\n",
    "    \n",
    "    \n",
    "def calculate_avg_mental_health():\n",
    "    df_dailies = load_dailies_data()\n",
    "    v = load_dailies_data()[['snapshot_id', 'day', 'stress', 'sleep', 'anxiety']].values\n",
    "    data = {}\n",
    "    for i in v:\n",
    "        data[(i[0], i[1])] = (i[2], i[3], i[4])\n",
    "    final_data = []\n",
    "    \n",
    "    for user in df_dailies['snapshot_id'].unique():\n",
    "        min_date = df_dailies[df_dailies['snapshot_id'] == user]['day'].min()\n",
    "        max_date = df_dailies[df_dailies['snapshot_id'] == user]['day'].max()\n",
    "        days_1 = timedelta(days=1)\n",
    "        days_3 = timedelta(days=3)\n",
    "\n",
    "        while(min_date < max_date):\n",
    "            date = min_date\n",
    "            before = date - days_3\n",
    "            after = date + days_3\n",
    "        \n",
    "            accumulate_stress = []\n",
    "            accumulate_sleep = []\n",
    "            accumulate_anxiety = []\n",
    "\n",
    "            while before < after:\n",
    "                if (user, before) in data:\n",
    "                    cache = data[(user, before)]\n",
    "                    if cache[0] == cache[0]:\n",
    "                        accumulate_stress.append(cache[0])\n",
    "                    if cache[1] == cache[1]:\n",
    "                        accumulate_sleep.append(cache[1])\n",
    "                    if cache[2] == cache[2]:\n",
    "                        accumulate_anxiety.append(cache[2])\n",
    "                before+=days_1\n",
    "\n",
    "            if len(accumulate_stress) > 0:\n",
    "                avg_stress = sum(accumulate_stress) / len(accumulate_stress)\n",
    "            else:\n",
    "                avg_stress = -1\n",
    "            if len(accumulate_sleep) > 0:\n",
    "                avg_sleep = sum(accumulate_sleep) / len(accumulate_sleep)\n",
    "            else:\n",
    "                avg_sleep = -1\n",
    "            if len(accumulate_anxiety) > 0:\n",
    "                avg_anxiety = sum(accumulate_anxiety) / len(accumulate_anxiety)\n",
    "            else:\n",
    "                avg_anxiety = -1\n",
    "\n",
    "            final_data.append([user, min_date, avg_stress, avg_sleep, avg_anxiety])\n",
    "            min_date+=days_1\n",
    "    final_data = pd.DataFrame(final_data, columns=['snapshot_id', 'day', 'stress', 'sleep', 'anxiety'])\n",
    "    return final_data[(final_data['stress'] != -1) & (final_data['sleep'] != -1) & (final_data['anxiety'] != -1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f7390c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snapshot_id</th>\n",
       "      <th>day</th>\n",
       "      <th>stress</th>\n",
       "      <th>sleep</th>\n",
       "      <th>anxiety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10003528337325499062</td>\n",
       "      <td>2018-02-28</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10003528337325499062</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003528337325499062</td>\n",
       "      <td>2018-03-02</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003528337325499062</td>\n",
       "      <td>2018-03-03</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003528337325499062</td>\n",
       "      <td>2018-03-04</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47115</th>\n",
       "      <td>9999689421615292586</td>\n",
       "      <td>2018-06-27</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47116</th>\n",
       "      <td>9999689421615292586</td>\n",
       "      <td>2018-06-28</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47117</th>\n",
       "      <td>9999689421615292586</td>\n",
       "      <td>2018-06-29</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47118</th>\n",
       "      <td>9999689421615292586</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47119</th>\n",
       "      <td>9999689421615292586</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44217 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                snapshot_id         day    stress     sleep   anxiety\n",
       "0      10003528337325499062  2018-02-28  1.666667  8.000000  2.000000\n",
       "1      10003528337325499062  2018-03-01  1.750000  8.000000  1.750000\n",
       "2      10003528337325499062  2018-03-02  1.600000  8.666667  1.600000\n",
       "3      10003528337325499062  2018-03-03  1.500000  8.666667  1.500000\n",
       "4      10003528337325499062  2018-03-04  1.500000  8.750000  1.333333\n",
       "...                     ...         ...       ...       ...       ...\n",
       "47115   9999689421615292586  2018-06-27  1.600000  8.666667  1.200000\n",
       "47116   9999689421615292586  2018-06-28  1.600000  8.500000  1.200000\n",
       "47117   9999689421615292586  2018-06-29  1.600000  8.500000  1.200000\n",
       "47118   9999689421615292586  2018-06-30  1.600000  8.000000  1.200000\n",
       "47119   9999689421615292586  2018-07-01  1.600000  8.000000  1.200000\n",
       "\n",
       "[44217 rows x 5 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_avg_mental_health()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d115b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stacked_df(dependent_variable):\n",
    "    try:\n",
    "        merged_data = pd.read_csv('Linear Regression/Relative Week/all_data_stacked_'+dependent_variable+'.csv')\n",
    "    except:\n",
    "        df_dailies = calculate_avg_mental_health()\n",
    "        df_social_media = load_social_media_data()\n",
    "        df_survey = load_survey_data()\n",
    "        df_demographics = load_demographics_data()\n",
    "\n",
    "        df_social_media['type'] = 'Social Media'\n",
    "        df_social_media['day'] = df_social_media['created_date']\n",
    "        \n",
    "        df_survey['day'] = -1\n",
    "        survey_rows = []\n",
    "#         print(df_survey.columns)\n",
    "        for i, row in df_survey.iterrows():\n",
    "            s_date = row['UpdatedBeginDate']\n",
    "            e_date = row['UpdatedEndDate']\n",
    "            delta = timedelta(days=1)\n",
    "\n",
    "            while s_date <= e_date:\n",
    "                r = row.copy(deep=True)\n",
    "                r['day'] = s_date\n",
    "                r['recency'] = (current_date - s_date).days\n",
    "                survey_rows.append(r.values)\n",
    "                s_date +=delta\n",
    "#         print(len(survey_rows[0]))\n",
    "#         print(df_survey.columns)\n",
    "#         print(df_social_media.columns)\n",
    "        df_survey = pd.DataFrame(survey_rows, columns=df_survey.columns)\n",
    "        df_survey['type'] = 'Survey'\n",
    "\n",
    "        df_dailies = df_dailies[['snapshot_id', dependent_variable, 'day']]\n",
    "\n",
    "        merged_data = pd.merge(df_dailies, df_demographics, how=\"inner\", on=\"snapshot_id\")\n",
    "        merged_data_sm = pd.merge(merged_data, df_social_media, how=\"inner\", on=[\"snapshot_id\", \"day\"])\n",
    "        merged_data_sr = pd.merge(merged_data, df_survey, how=\"inner\", on=[\"snapshot_id\", \"day\"])\n",
    "\n",
    "        merged_data = pd.concat([merged_data_sm,merged_data_sr],ignore_index=True)\n",
    "        \n",
    "        merged_data['recency'] = (merged_data['recency'] - merged_data['recency'].min()) / (merged_data['recency'].max() - merged_data['recency'].min())    \n",
    "        merged_data.to_csv('Linear Regression/Relative Week/all_data_stacked_'+dependent_variable+'.csv', index=False)\n",
    "        \n",
    "    merged_data = merged_data.drop(columns=['created_date', 'UpdatedBeginDate', 'UpdatedEndDate'])\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8e9444a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_merged_df(dependent_variable):\n",
    "    try:\n",
    "        merged_data = pd.read_csv('Linear Regression/Relative Week/all_data_'+dependent_variable+'.csv')\n",
    "    except:\n",
    "        df_dailies = calculate_avg_mental_health()\n",
    "        df_social_media = load_social_media_data()\n",
    "        df_survey = load_survey_data()\n",
    "        df_demographics = load_demographics_data()\n",
    "        df_social_media.rename(columns=lambda x: x+'_sm', inplace=True)\n",
    "        df_social_media = df_social_media.rename(columns={\n",
    "            'snapshot_id_sm': 'snapshot_id',\n",
    "            'created_date_sm': 'day'\n",
    "        })\n",
    "        df_social_media['recency_sm'] = (df_social_media['recency_sm'] - df_social_media['recency_sm'].min()) / (df_social_media['recency_sm'].max() - df_social_media['recency_sm'].min())\n",
    "        df_survey['day'] = -1\n",
    "        survey_rows = []\n",
    "        for i, row in df_survey.iterrows():\n",
    "            s_date = row['UpdatedBeginDate']\n",
    "            e_date = row['UpdatedEndDate']\n",
    "            delta = timedelta(days=1)\n",
    "\n",
    "            while s_date <= e_date:\n",
    "                r = row.copy(deep=True)\n",
    "                r['day'] = s_date\n",
    "                r['recency'] = (current_date - s_date).days\n",
    "                survey_rows.append(r.values)\n",
    "                s_date +=delta\n",
    "\n",
    "        df_survey = pd.DataFrame(survey_rows, columns=df_survey.columns)\n",
    "        df_survey.rename(columns=lambda x: x+'_sr', inplace=True)\n",
    "        df_survey = df_survey.rename(columns={\n",
    "            'snapshot_id_sr': 'snapshot_id',\n",
    "            'day_sr' : 'day'\n",
    "        })\n",
    "\n",
    "        df_dailies = df_dailies[['snapshot_id', dependent_variable, 'day']]\n",
    "        df_survey['recency_sr'] = (df_survey['recency_sr'] - df_survey['recency_sr'].min()) / (df_survey['recency_sr'].max() - df_survey['recency_sr'].min())    \n",
    "\n",
    "        merged_data = pd.merge(df_dailies, df_demographics, how=\"inner\", on=\"snapshot_id\")\n",
    "        merged_data = pd.merge(merged_data, df_social_media, how=\"left\", on=[\"snapshot_id\", \"day\"])\n",
    "        merged_data = pd.merge(merged_data, df_survey, how=\"left\", on=[\"snapshot_id\", \"day\"])\n",
    "\n",
    "        merged_data.to_csv('Linear Regression/Relative Week/all_data_'+dependent_variable+'.csv', index=False)\n",
    "        \n",
    "#     merged_data = merged_data.drop(columns=['created_date_sm', 'UpdatedBeginDate_sr', 'UpdatedEndDate_sr'])\n",
    "    return merged_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e9205",
   "metadata": {},
   "source": [
    "## Run Regression  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "ee32a9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_variables = ['shipley_vocab', 'shipley_abs', 'openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism', 'pos_affect', 'neg_affect', 'stai_trait', 'education_level', 'psqi', 'age', 'gender']\n",
    "sr_life_event_variables = ['Anticipation_sr', 'LifeEventType_sr', 'valence_sr', 'recency_sr', 'status_sr', 'Intimacy_sr', 'Scope_sr', 'significance_sr']\n",
    "sm_life_event_variables = ['Anticipation_sm', 'LifeEventType_sm', 'valence_sm', 'recency_sm', 'status_sm', 'Intimacy_sm', 'Scope_sm', 'significance_sm']\n",
    "life_event_variables = ['Anticipation', 'LifeEventType', 'valence', 'recency', 'status', 'Intimacy', 'Scope', 'significance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "86e26066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(data, formula):\n",
    "    model = smf.ols(formula=formula, data = data)\n",
    "    result = model.fit()\n",
    "    summary = result.summary2()\n",
    "    a = summary.tables[1]\n",
    "    a['significance'] = a['P>|t|'].apply(lambda x: star_pvals(x))\n",
    "#     a.sort_values(by=['P>|t|'], inplace=True)\n",
    "    a['sig'] = a['P>|t|'].apply(lambda x: no_star_pvals(x))\n",
    "    a['abs_coef'] = a['Coef.'].abs()\n",
    "    a.sort_values(['sig','abs_coef'], ascending=[False, False], inplace=True)\n",
    "    a.drop(columns=['sig', 'abs_coef'], inplace=True)\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "79df040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_r(data, formula):\n",
    "    model = smf.ols(formula=formula, data = data)\n",
    "    result = model.fit_regularized(alpha=0.001, L1_wt=0)\n",
    "    model, result = convert_regularized_to_ols(model, result)\n",
    "    summary = result.summary2()\n",
    "    a = summary.tables[1]\n",
    "    a['significance'] = a['P>|t|'].apply(lambda x: star_pvals(x))\n",
    "    a['sig'] = a['P>|t|'].apply(lambda x: no_star_pvals(x))\n",
    "    a['abs_coef'] = a['Coef.'].abs()\n",
    "    a.sort_values(['sig','abs_coef'], ascending=[False, False], inplace=True)\n",
    "    a.drop(columns=['sig', 'abs_coef'], inplace=True)\n",
    "#     a.sort_values(by=['P>|t|'], inplace=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c889bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(data, formula):\n",
    "    model = smf.ols(formula=formula, data = data).fit()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "9d54a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_file_r(data, formula, filename):\n",
    "    t = get_summary_r(data, formula).as_text()\n",
    "\n",
    "    with open('Linear Regression/Relative Week/summary/'+filename+'.txt', 'w') as the_file:\n",
    "        the_file.write(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "b00e89a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_file(data, formula, filename):\n",
    "    t = get_summary(data, formula).as_text()\n",
    "\n",
    "    with open('Linear Regression/Relative Week/summary/'+filename+'.txt', 'w') as the_file:\n",
    "        the_file.write(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "ca7a3a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_files(dependent_variable):\n",
    "    data = build_merged_df(dependent_variable)\n",
    "    all_data = data[(data['LifeEventType_sr'].notnull()) & (data['LifeEventType_sm'].notnull())]\n",
    "    all_data = all_data[all_data[dependent_variable].notnull()]\n",
    "\n",
    "    generate_summary_file(all_data, dependent_variable+'~'+' + '.join(control_variables), 'all_demo_trait_'+dependent_variable)\n",
    "    generate_summary_file(all_data, dependent_variable+'~'+' + '.join(sm_life_event_variables+sr_life_event_variables), 'all_sm_sr_'+dependent_variable)\n",
    "    generate_summary_file(all_data, dependent_variable+'~'+' + '.join(control_variables+sr_life_event_variables+sm_life_event_variables), 'all_sm_sr_demo_trait_'+dependent_variable)\n",
    "    generate_summary_file_r(all_data, dependent_variable+'~'+' + '.join(control_variables), 'all_demo_trait_'+dependent_variable+'_regularized')\n",
    "    generate_summary_file_r(all_data, dependent_variable+'~'+' + '.join(sm_life_event_variables+sr_life_event_variables), 'all_sm_sr_'+dependent_variable+'_regularized')\n",
    "    generate_summary_file_r(all_data, dependent_variable+'~'+' + '.join(control_variables+sr_life_event_variables+sm_life_event_variables), 'all_sm_sr_demo_trait_'+dependent_variable+'_regularized')\n",
    "    all_variables = ' + '.join(control_variables+sr_life_event_variables+sm_life_event_variables)\n",
    "    combined_control = ' + '.join(control_variables)\n",
    "    combined_life_event = ' + '.join(sr_life_event_variables+sm_life_event_variables)\n",
    "    final_var = '('+all_variables+')**2 - ' + ' ('+combined_control+')**2 - ' + ' ('+combined_life_event+')**2' + ' + ' + all_variables\n",
    "\n",
    "    generate_summary_file(all_data, ModelDesc.from_formula(dependent_variable+'~'+final_var).describe(), 'all_sm_sr_demo_trait_interaction_'+dependent_variable)\n",
    "    generate_summary_file_r(all_data, ModelDesc.from_formula(dependent_variable+'~'+final_var).describe(), 'all_sm_sr_demo_trait_interaction_'+dependent_variable+'_regularized')\n",
    "\n",
    "#     data = build_stacked_df(dependent_variable)\n",
    "#     generate_summary_file(data, dependent_variable+'~'+' + '.join(control_variables), 'stacked_demo_trait_'+dependent_variable)\n",
    "#     generate_summary_file(data, dependent_variable+'~'+' + '.join(life_event_variables), 'stacked_life_events_'+dependent_variable)\n",
    "#     generate_summary_file(data, dependent_variable+'~'+' + '.join(control_variables+life_event_variables + ['type']), 'stacked_demo_trait_life_events_'+dependent_variable)\n",
    "#     all_variables = ' + '.join(control_variables + life_event_variables + ['type'])\n",
    "#     combined_control = ' + '.join(control_variables+['type'])\n",
    "#     combined_life_event = ' + '.join(life_event_variables)\n",
    "#     final_var = '('+all_variables+')**2 - ' + ' ('+combined_control+')**2 - ' + ' ('+combined_life_event+')**2' + ' + ' + all_variables\n",
    "    \n",
    "#     generate_summary_file(data, ModelDesc.from_formula(dependent_variable+'~'+final_var).describe(), 'stacked_demo_trait_life_events_interaction_'+dependent_variable)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "8d0fe260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/regression/linear_model.py:1860: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n"
     ]
    }
   ],
   "source": [
    "a = ' + '.join(control_variables)\n",
    "b = ' + '.join(sr_life_event_variables)\n",
    "c = ' + '.join(sm_life_event_variables)\n",
    "\n",
    "final_var = ' (' + a + ' + ' + c +')**2' + ' - ('+a+')**2' + ' + ' + a + '+' + b\n",
    "\n",
    "data = build_merged_df('stress')\n",
    "all_data = data[(data['LifeEventType_sr'].notnull()) & (data['LifeEventType_sm'].notnull())]\n",
    "all_data = all_data[all_data['stress'].notnull()]\n",
    "\n",
    "generate_summary_file(all_data, ModelDesc.from_formula('stress'+'~'+final_var).describe(), 'all_stress_life_event_interaction')\n",
    "generate_summary_file_r(all_data, ModelDesc.from_formula('stress'+'~'+final_var).describe(), 'all_stress_life_event_interaction_regularized')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "id": "a79a57c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = ' + '.join(control_variables)\n",
    "b = ' + '.join(sr_life_event_variables)\n",
    "c = ' + '.join(sm_life_event_variables)\n",
    "\n",
    "final_var = a + ' + (' + b + ')**2 + ' + '+ (' + c + ')**2'\n",
    "\n",
    "data = build_merged_df('sleep')\n",
    "all_data = data[(data['LifeEventType_sr'].notnull()) & (data['LifeEventType_sm'].notnull())]\n",
    "all_data = all_data[all_data['sleep'].notnull()]\n",
    "\n",
    "generate_summary_file(all_data, ModelDesc.from_formula('sleep'+'~'+final_var).describe(), 'all_sleep_sm_sr_interaction')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "88ddebfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/regression/linear_model.py:1860: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n",
      "/usr/local/lib/python3.6/dist-packages/statsmodels/regression/linear_model.py:1860: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n",
      "/usr/local/lib/python3.6/dist-packages/statsmodels/regression/linear_model.py:1860: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n"
     ]
    }
   ],
   "source": [
    "generate_summary_files('stress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "166465b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/regression/linear_model.py:1860: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n",
      "/usr/local/lib/python3.6/dist-packages/statsmodels/regression/linear_model.py:1860: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n",
      "/usr/local/lib/python3.6/dist-packages/statsmodels/regression/linear_model.py:1860: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n"
     ]
    }
   ],
   "source": [
    "generate_summary_files('sleep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "fec24c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/regression/linear_model.py:1860: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n",
      "/usr/local/lib/python3.6/dist-packages/statsmodels/regression/linear_model.py:1860: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n",
      "/usr/local/lib/python3.6/dist-packages/statsmodels/regression/linear_model.py:1860: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n"
     ]
    }
   ],
   "source": [
    "generate_summary_files('anxiety')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "960fb773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_regularized_to_ols(model, results):\n",
    "    pinv_wexog,_ = pinv_extended(model.wexog)\n",
    "    normalized_cov_params = np.dot(pinv_wexog, np.transpose(pinv_wexog))\n",
    "\n",
    "    results = sm.regression.linear_model.OLSResults(model, results.params, normalized_cov_params)\n",
    "    return model, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "acecdac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regression_regularized(data, dependent_variable, variables):\n",
    "\n",
    "    control_data = data[variables['control']+[dependent_variable]].dropna()\n",
    "    train_data, test_data = train_test_split(control_data, test_size=0.20, random_state=805)\n",
    "    f_exp = test_data[dependent_variable].values\n",
    "\n",
    "    baseline_formula = dependent_variable+'~'+' + '.join(variables['control'])\n",
    "    baseline_model = smf.ols(formula=baseline_formula,\n",
    "                  data = control_data)\n",
    "    baseline = baseline_model.fit_regularized(alpha=0.001, L1_wt=0.5)\n",
    "    baseline_model, baseline = convert_regularized_to_ols(baseline_model, baseline)\n",
    "    \n",
    "    baseline_train = smf.ols(formula=baseline_formula,\n",
    "                  data = train_data).fit_regularized()\n",
    "    f_obs = baseline_train.predict(test_data).values\n",
    "    pearson_baseline = scipy.stats.pearsonr(f_obs, f_exp)\n",
    "    \n",
    "    \n",
    "    life_events_data = data[variables['life_events']+[dependent_variable]].dropna()    \n",
    "    train_data, test_data = train_test_split(life_events_data, test_size=0.20, random_state=805)\n",
    "    f_exp = test_data[dependent_variable].values\n",
    "\n",
    "    life_events_formula = dependent_variable+'~'+' + '.join(variables['life_events'])\n",
    "    life_events_model = smf.ols(formula=life_events_formula, data = life_events_data)\n",
    "    life_events = life_events_model.fit_regularized(alpha=0.001, L1_wt=0.5) \n",
    "    life_events_model, life_events = convert_regularized_to_ols(life_events_model, life_events)\n",
    "    life_events_train = smf.ols(formula=life_events_formula, data = train_data).fit_regularized()     \n",
    "    f_obs = life_events_train.predict(test_data).values\n",
    "    pearson_life_events = scipy.stats.pearsonr(f_obs, f_exp)    \n",
    "\n",
    "    \n",
    "    all_variable_data = data[variables['all_variables']+[dependent_variable]].dropna()\n",
    "    train_data, test_data = train_test_split(all_variable_data, test_size=0.20, random_state=805)\n",
    "    f_exp = test_data[dependent_variable].values    \n",
    "    \n",
    "    all_variables_formula = dependent_variable+'~'+' + '.join(variables['all_variables'])\n",
    "    all_variables_model = smf.ols(formula=all_variables_formula, data = all_variable_data)\n",
    "    all_variables = all_variables_model.fit_regularized(alpha=0.001, L1_wt=0.5) \n",
    "    all_variables_model, all_variables = convert_regularized_to_ols(all_variables_model, all_variables)\n",
    "\n",
    "    all_variables_train = smf.ols(formula=all_variables_formula, data = train_data).fit_regularized() \n",
    "    f_obs = all_variables_train.predict(test_data).values\n",
    "    pearson_all_variables = scipy.stats.pearsonr(f_obs, f_exp)    \n",
    "\n",
    "    \n",
    "    print(\"Baseline R-square adj\", baseline.rsquared_adj)\n",
    "    print(\"Life Events R-square adj\", life_events.rsquared_adj)\n",
    "    print(\"All Variables R-square adj\", all_variables.rsquared_adj)\n",
    "    print()\n",
    "    print(anova_lm(baseline, life_events))\n",
    "    print(anova_lm(baseline, all_variables))\n",
    "    print(anova_lm(life_events, all_variables))\n",
    "    print()\n",
    "    print(\"Baseline pearson\", pearson_baseline)\n",
    "    print(\"Life Events pearson\", pearson_life_events)\n",
    "    print(\"All Variables pearson\", pearson_all_variables)    \n",
    "    return all_variables.rsquared_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "76dd12f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regression(data, dependent_variable, variables):\n",
    "\n",
    "    control_data = data[variables['control']+[dependent_variable]].dropna()\n",
    "    train_data, test_data = train_test_split(control_data, test_size=0.20, random_state=805)\n",
    "    f_exp = test_data[dependent_variable].values\n",
    "\n",
    "    baseline_formula = dependent_variable+'~'+' + '.join(variables['control'])\n",
    "    baseline = smf.ols(formula=baseline_formula,\n",
    "                  data = control_data).fit()\n",
    "    baseline_train = smf.ols(formula=baseline_formula,\n",
    "                  data = train_data).fit()\n",
    "    f_obs = baseline_train.predict(test_data).values\n",
    "    pearson_baseline = scipy.stats.pearsonr(f_obs, f_exp)\n",
    "    \n",
    "    \n",
    "    life_events_data = data[variables['life_events']+[dependent_variable]].dropna()    \n",
    "    train_data, test_data = train_test_split(life_events_data, test_size=0.20, random_state=805)\n",
    "    f_exp = test_data[dependent_variable].values\n",
    "\n",
    "    life_events_formula = dependent_variable+'~'+' + '.join(variables['life_events'])\n",
    "    life_events = smf.ols(formula=life_events_formula, data = life_events_data).fit() \n",
    "    life_events_train = smf.ols(formula=life_events_formula, data = train_data).fit()     \n",
    "    f_obs = life_events_train.predict(test_data).values\n",
    "    pearson_life_events = scipy.stats.pearsonr(f_obs, f_exp)    \n",
    "\n",
    "    \n",
    "    all_variable_data = data[variables['all_variables']+[dependent_variable]].dropna()\n",
    "    train_data, test_data = train_test_split(all_variable_data, test_size=0.20, random_state=805)\n",
    "    f_exp = test_data[dependent_variable].values    \n",
    "    \n",
    "    all_variables_formula = dependent_variable+'~'+' + '.join(variables['all_variables'])\n",
    "    all_variables = smf.ols(formula=all_variables_formula, data = all_variable_data).fit() \n",
    "    all_variables_train = smf.ols(formula=all_variables_formula, data = train_data).fit() \n",
    "    f_obs = all_variables_train.predict(test_data).values\n",
    "    pearson_all_variables = scipy.stats.pearsonr(f_obs, f_exp)    \n",
    "\n",
    "    print(\"Baseline R-square adj\", baseline.rsquared_adj)\n",
    "    print(\"Life Events R-square adj\", life_events.rsquared_adj)\n",
    "    print(\"All Variables R-square adj\", all_variables.rsquared_adj)\n",
    "    print()\n",
    "    print(anova_lm(baseline, life_events))\n",
    "    print(anova_lm(baseline, all_variables))\n",
    "    print(anova_lm(life_events, all_variables))\n",
    "    print()\n",
    "    print(\"Baseline pearson\", pearson_baseline)\n",
    "    print(\"Life Events pearson\", pearson_life_events)\n",
    "    print(\"All Variables pearson\", pearson_all_variables)    \n",
    "    return all_variables.rsquared_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "f336ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_regression(dependent_variable, is_regularized=False):\n",
    "    data = build_merged_df(dependent_variable)\n",
    "\n",
    "    social_media_data = data[data['LifeEventType_sm'].notnull()]\n",
    "    social_media_data = social_media_data[social_media_data[dependent_variable].notnull()]\n",
    "\n",
    "    social_media_variables = {\n",
    "        'control': control_variables,\n",
    "        'life_events': sm_life_event_variables,\n",
    "        'all_variables': sm_life_event_variables + control_variables\n",
    "    }\n",
    "\n",
    "    survey_data = data[data['LifeEventType_sr'].notnull()]\n",
    "    survey_data = survey_data[survey_data[dependent_variable].notnull()]\n",
    "    survey_variables = {\n",
    "        'control': control_variables,\n",
    "        'life_events': sr_life_event_variables,\n",
    "        'all_variables': sr_life_event_variables + control_variables\n",
    "    }\n",
    "    \n",
    "    all_data = data[(data['LifeEventType_sr'].notnull()) & (data['LifeEventType_sm'].notnull())]\n",
    "    all_data = all_data[all_data[dependent_variable].notnull()]\n",
    "    all_data_variables = {\n",
    "        'control': control_variables,\n",
    "        'life_events': sm_life_event_variables + sr_life_event_variables,\n",
    "        'all_variables': sm_life_event_variables + sr_life_event_variables + control_variables\n",
    "    }\n",
    "    \n",
    "    \n",
    "#     print(\"---------SOCIAL MEDIA---------\")\n",
    "#     if is_regularized:\n",
    "#         run_regression_regularized(social_media_data, dependent_variable, social_media_variables)\n",
    "#     else:\n",
    "#         run_regression(social_media_data, dependent_variable, social_media_variables)\n",
    "#     print()\n",
    "    \n",
    "#     print(\"---------SURVEY---------\")\n",
    "#     if is_regularized:\n",
    "#         run_regression_regularized(survey_data, dependent_variable, survey_variables)\n",
    "#     else:\n",
    "#         run_regression(survey_data, dependent_variable, survey_variables)\n",
    "#     print()\n",
    "    \n",
    "    print(\"---------SOCIAL MEDIA + SURVEY---------\")\n",
    "    if is_regularized:\n",
    "        run_regression_regularized(all_data, dependent_variable, all_data_variables) \n",
    "    else:\n",
    "        run_regression(all_data, dependent_variable, all_data_variables)\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ac51284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_stacked_regression(dependent_variable):\n",
    "    data = build_stacked_df(dependent_variable)\n",
    "\n",
    "    all_data = data[data[dependent_variable].notnull()]\n",
    "    all_data_variables = {\n",
    "        'control': control_variables,\n",
    "        'life_events': life_event_variables,\n",
    "        'all_variables': life_event_variables + control_variables + ['type']\n",
    "    }\n",
    "    \n",
    "    print(\"---------SOCIAL MEDIA + SURVEY---------\")\n",
    "    run_regression(all_data, dependent_variable, all_data_variables)\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a64209",
   "metadata": {},
   "source": [
    "### Stress "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "25ba85d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------SOCIAL MEDIA + SURVEY---------\n",
      "Baseline R-square adj 0.16422305748023447\n",
      "Life Events R-square adj 0.3179276386084303\n",
      "All Variables R-square adj 0.3430250035317137\n",
      "\n",
      "   df_resid        ssr  df_diff    ss_diff         F    Pr(>F)\n",
      "0     131.0  81.553530      0.0        NaN       NaN       NaN\n",
      "1     125.0  63.506993      6.0  18.046537  5.920128  0.000018\n",
      "   df_resid        ssr  df_diff    ss_diff         F    Pr(>F)\n",
      "0     131.0  81.553530      0.0        NaN       NaN       NaN\n",
      "1     109.0  53.340419     22.0  28.213111  2.620586  0.000534\n",
      "   df_resid        ssr  df_diff    ss_diff         F    Pr(>F)\n",
      "0     125.0  63.506993      0.0        NaN       NaN       NaN\n",
      "1     109.0  53.340419     16.0  10.166574  1.298448  0.211203\n",
      "\n",
      "Baseline pearson (0.31611918522334476, 0.08878555471555973)\n",
      "Life Events pearson (0.41344540003192787, 0.02314694853629488)\n",
      "All Variables pearson (0.44591655005369873, 0.013520427457533346)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_all_regression('stress', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "d010d51b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------SOCIAL MEDIA---------\n",
      "Baseline R-square adj 0.1008882646701027\n",
      "Life Events R-square adj 0.06087553832060044\n",
      "All Variables R-square adj 0.1555923531285176\n",
      "\n",
      "   df_resid         ssr  df_diff   ss_diff         F  Pr(>F)\n",
      "0     615.0  252.777309      0.0       NaN       NaN     NaN\n",
      "1     619.0  265.743779     -4.0 -12.96647  7.550736     NaN\n",
      "   df_resid         ssr  df_diff    ss_diff         F    Pr(>F)\n",
      "0     615.0  252.777309      0.0        NaN       NaN       NaN\n",
      "1     603.0  232.765588     12.0  20.011721  4.320179  0.000001\n",
      "   df_resid         ssr  df_diff    ss_diff         F        Pr(>F)\n",
      "0     619.0  265.743779      0.0        NaN       NaN           NaN\n",
      "1     603.0  232.765588     16.0  32.978191  5.339559  1.187143e-10\n",
      "\n",
      "Baseline pearson (0.3269397950664338, 0.00017568539380028838)\n",
      "Life Events pearson (0.22618431090705632, 0.01055815059769284)\n",
      "All Variables pearson (0.3926633185717482, 4.968582704067654e-06)\n",
      "\n",
      "---------SURVEY---------\n",
      "Baseline R-square adj 0.1924691837833341\n",
      "Life Events R-square adj 0.03678556894646301\n",
      "All Variables R-square adj 0.2153744037240819\n",
      "\n",
      "   df_resid          ssr  df_diff     ss_diff           F  Pr(>F)\n",
      "0    6729.0  2594.956332      0.0         NaN         NaN     NaN\n",
      "1    6733.0  3097.077095     -4.0 -502.120763  272.900786     NaN\n",
      "   df_resid          ssr  df_diff   ss_diff          F        Pr(>F)\n",
      "0    6729.0  2594.956332      0.0       NaN        NaN           NaN\n",
      "1    6717.0  2516.855263     12.0  78.10107  17.369721  2.476653e-37\n",
      "   df_resid          ssr  df_diff     ss_diff          F         Pr(>F)\n",
      "0    6733.0  3097.077095      0.0         NaN        NaN            NaN\n",
      "1    6717.0  2516.855263     16.0  580.221832  96.781242  2.073450e-287\n",
      "\n",
      "Baseline pearson (0.43772326188723615, 2.7164307283142327e-64)\n",
      "Life Events pearson (0.21280010499341798, 2.7400163978889378e-15)\n",
      "All Variables pearson (0.4660663942135938, 9.58028292592294e-74)\n",
      "\n",
      "---------SOCIAL MEDIA + SURVEY---------\n",
      "Baseline R-square adj 0.21732855041271915\n",
      "Life Events R-square adj 0.33256419094137235\n",
      "All Variables R-square adj 0.42319426459733245\n",
      "\n",
      "   df_resid        ssr  df_diff    ss_diff         F    Pr(>F)\n",
      "0     131.0  76.371597      0.0        NaN       NaN       NaN\n",
      "1     125.0  62.144200      6.0  14.227397  4.769618  0.000207\n",
      "   df_resid        ssr  df_diff    ss_diff         F    Pr(>F)\n",
      "0     131.0  76.371597      0.0        NaN       NaN       NaN\n",
      "1     109.0  46.831401     22.0  29.540196  3.125216  0.000045\n",
      "   df_resid        ssr  df_diff    ss_diff         F    Pr(>F)\n",
      "0     125.0  62.144200      0.0        NaN       NaN       NaN\n",
      "1     109.0  46.831401     16.0  15.312799  2.227532  0.007988\n",
      "\n",
      "Baseline pearson (0.35148595004734473, 0.056826558385922266)\n",
      "Life Events pearson (0.3793668911361632, 0.03867807546418057)\n",
      "All Variables pearson (0.4673537955858652, 0.009215033347323936)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_all_regression('stress', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c6a39140",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------SOCIAL MEDIA + SURVEY---------\n",
      "Baseline R-square adj 0.1764291746827119\n",
      "Life Events R-square adj 0.037265771142125925\n",
      "All Variables R-square adj 0.20533117142664092\n",
      "\n",
      "   df_resid          ssr  df_diff     ss_diff           F  Pr(>F)\n",
      "0    7296.0  2855.129332      0.0         NaN         NaN     NaN\n",
      "1    7299.0  3338.948984     -3.0 -483.819652  352.546031     NaN\n",
      "   df_resid          ssr  df_diff     ss_diff          F        Pr(>F)\n",
      "0    7296.0  2855.129332      0.0         NaN        NaN           NaN\n",
      "1    7282.0  2749.646473     14.0  105.482859  19.953895  2.572230e-50\n",
      "   df_resid          ssr  df_diff     ss_diff          F         Pr(>F)\n",
      "0    7299.0  3338.948984      0.0         NaN        NaN            NaN\n",
      "1    7282.0  2749.646473     17.0  589.302511  91.804334  7.315350e-291\n",
      "\n",
      "Baseline pearson (0.43201629980000694, 1.3966803892644736e-67)\n",
      "Life Events pearson (0.21195019763458153, 2.5426632972018607e-16)\n",
      "All Variables pearson (0.455476884757731, 7.856886523692654e-76)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_stacked_regression('stress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "06442bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------SOCIAL MEDIA + SURVEY---------\n",
      "Baseline R-square adj 0.31273109715001657\n",
      "Life Events R-square adj 0.1847110446316672\n",
      "All Variables R-square adj 0.3686259005736009\n",
      "\n",
      "   df_resid         ssr  df_diff    ss_diff         F  Pr(>F)\n",
      "0     131.0  201.950365      0.0        NaN       NaN     NaN\n",
      "1     125.0  228.595789      6.0 -26.645424 -2.428361     1.0\n",
      "   df_resid         ssr  df_diff    ss_diff         F    Pr(>F)\n",
      "0     131.0  201.950365      0.0        NaN       NaN       NaN\n",
      "1     109.0  154.368937     22.0  47.581428  1.527149  0.079689\n",
      "   df_resid         ssr  df_diff    ss_diff         F   Pr(>F)\n",
      "0     125.0  228.595789      0.0        NaN       NaN      NaN\n",
      "1     109.0  154.368937     16.0  74.226852  3.275727  0.00012\n",
      "\n",
      "Baseline pearson (0.5769699009377611, 0.0008444798674519633)\n",
      "Life Events pearson (0.4255037779923419, 0.01906743312753837)\n",
      "All Variables pearson (0.50393478307934, 0.004521865835320618)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_all_regression('sleep', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "0773a6a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------SOCIAL MEDIA---------\n",
      "Baseline R-square adj 0.12888423999983512\n",
      "Life Events R-square adj 0.03501048666045281\n",
      "All Variables R-square adj 0.1460516677563436\n",
      "\n",
      "   df_resid          ssr  df_diff     ss_diff          F  Pr(>F)\n",
      "0     615.0   986.807101      0.0         NaN        NaN     NaN\n",
      "1     619.0  1100.257968     -4.0 -113.450866  15.956732     NaN\n",
      "   df_resid         ssr  df_diff    ss_diff         F    Pr(>F)\n",
      "0     615.0  986.807101      0.0        NaN       NaN       NaN\n",
      "1     603.0  948.484387     12.0  38.322715  2.030309  0.019829\n",
      "   df_resid          ssr  df_diff     ss_diff         F        Pr(>F)\n",
      "0     619.0  1100.257968      0.0         NaN       NaN           NaN\n",
      "1     603.0   948.484387     16.0  151.773581  6.030639  1.998141e-12\n",
      "\n",
      "Baseline pearson (0.28058756354422637, 0.0013971575366344795)\n",
      "Life Events pearson (0.2284233227822866, 0.0097947700864724)\n",
      "All Variables pearson (0.3168717807213702, 0.00028380387240432636)\n",
      "\n",
      "---------SURVEY---------\n",
      "Baseline R-square adj 0.070663358525062\n",
      "Life Events R-square adj 0.030226411683058618\n",
      "All Variables R-square adj 0.11338975859953115\n",
      "\n",
      "   df_resid          ssr  df_diff     ss_diff          F  Pr(>F)\n",
      "0    6729.0  9235.478052      0.0         NaN        NaN     NaN\n",
      "1    6733.0  9643.057537     -4.0 -407.579484  71.145294     NaN\n",
      "   df_resid          ssr  df_diff     ss_diff          F        Pr(>F)\n",
      "0    6729.0  9235.478052      0.0         NaN        NaN           NaN\n",
      "1    6717.0  8795.162816     12.0  440.315237  28.022955  5.079081e-63\n",
      "   df_resid          ssr  df_diff     ss_diff          F         Pr(>F)\n",
      "0    6733.0  9643.057537      0.0         NaN        NaN            NaN\n",
      "1    6717.0  8795.162816     16.0  847.894721  40.471883  2.292833e-121\n",
      "\n",
      "Baseline pearson (0.23509711596342833, 2.0778968878367608e-18)\n",
      "Life Events pearson (0.16833813858075344, 4.850261365517216e-10)\n",
      "All Variables pearson (0.3162967191927879, 9.535390754505845e-33)\n",
      "\n",
      "---------SOCIAL MEDIA + SURVEY---------\n",
      "Baseline R-square adj 0.3448969813112489\n",
      "Life Events R-square adj 0.24849049863923833\n",
      "All Variables R-square adj 0.4998412793128557\n",
      "\n",
      "   df_resid         ssr  df_diff   ss_diff         F  Pr(>F)\n",
      "0     131.0  192.498589      0.0       NaN       NaN     NaN\n",
      "1     125.0  210.712909      6.0 -18.21432 -1.800863     1.0\n",
      "   df_resid         ssr  df_diff   ss_diff        F    Pr(>F)\n",
      "0     131.0  192.498589      0.0       NaN      NaN       NaN\n",
      "1     109.0  122.287199     22.0  70.21139  2.84466  0.000179\n",
      "   df_resid         ssr  df_diff   ss_diff        F        Pr(>F)\n",
      "0     125.0  210.712909      0.0       NaN      NaN           NaN\n",
      "1     109.0  122.287199     16.0  88.42571  4.92611  1.688936e-07\n",
      "\n",
      "Baseline pearson (0.6165742382477141, 0.00028523867723617263)\n",
      "Life Events pearson (0.541898106381157, 0.00198110232061923)\n",
      "All Variables pearson (0.44715190412604855, 0.013233421136045623)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_all_regression('sleep', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5d951479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------SOCIAL MEDIA + SURVEY---------\n",
      "Baseline R-square adj 0.06471969801113886\n",
      "Life Events R-square adj 0.025825310498153065\n",
      "All Variables R-square adj 0.09508662229032705\n",
      "\n",
      "   df_resid           ssr  df_diff     ss_diff          F  Pr(>F)\n",
      "0    7296.0  10189.902958      0.0         NaN        NaN     NaN\n",
      "1    7299.0  10618.022480     -3.0 -428.119522  98.098756     NaN\n",
      "   df_resid           ssr  df_diff     ss_diff          F        Pr(>F)\n",
      "0    7296.0  10189.902958      0.0         NaN        NaN           NaN\n",
      "1    7282.0   9840.136395     14.0  349.766563  18.488421  3.284829e-46\n",
      "   df_resid           ssr  df_diff     ss_diff          F         Pr(>F)\n",
      "0    7299.0  10618.022480      0.0         NaN        NaN            NaN\n",
      "1    7282.0   9840.136395     17.0  777.886085  33.862314  5.700353e-107\n",
      "\n",
      "Baseline pearson (0.2606047902620883, 3.862609272566685e-24)\n",
      "Life Events pearson (0.1782973520119464, 6.464970542162705e-12)\n",
      "All Variables pearson (0.3215680962420773, 1.5169420758665593e-36)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_stacked_regression('sleep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "a7a7eb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------SOCIAL MEDIA + SURVEY---------\n",
      "Baseline R-square adj 0.24627583377637408\n",
      "Life Events R-square adj 0.25932666364816437\n",
      "All Variables R-square adj 0.3349336128389523\n",
      "\n",
      "   df_resid        ssr  df_diff   ss_diff         F    Pr(>F)\n",
      "0     131.0  54.675338      0.0       NaN       NaN       NaN\n",
      "1     125.0  51.267774      6.0  3.407564  1.384708  0.225832\n",
      "   df_resid        ssr  df_diff    ss_diff         F   Pr(>F)\n",
      "0     131.0  54.675338      0.0        NaN       NaN      NaN\n",
      "1     109.0  40.142021     22.0  14.533317  1.793781  0.02591\n",
      "   df_resid        ssr  df_diff    ss_diff         F    Pr(>F)\n",
      "0     125.0  51.267774      0.0        NaN       NaN       NaN\n",
      "1     109.0  40.142021     16.0  11.125753  1.888151  0.028937\n",
      "\n",
      "Baseline pearson (0.4583087966953588, 0.010864283357161187)\n",
      "Life Events pearson (0.4327004317257537, 0.016929535687524738)\n",
      "All Variables pearson (0.5093966370918712, 0.00403861048919734)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_all_regression('anxiety', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "82a4a682",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------SOCIAL MEDIA---------\n",
      "Baseline R-square adj 0.16702073399945816\n",
      "Life Events R-square adj 0.058810636910408776\n",
      "All Variables R-square adj 0.20562051777629053\n",
      "\n",
      "   df_resid         ssr  df_diff    ss_diff          F  Pr(>F)\n",
      "0     615.0  175.905995      0.0        NaN        NaN     NaN\n",
      "1     619.0  200.050201     -4.0 -24.144206  18.676892     NaN\n",
      "   df_resid         ssr  df_diff    ss_diff         F    Pr(>F)\n",
      "0     615.0  175.905995      0.0        NaN       NaN       NaN\n",
      "1     603.0  164.481351     12.0  11.424644  3.490295  0.000052\n",
      "   df_resid         ssr  df_diff    ss_diff         F        Pr(>F)\n",
      "0     619.0  200.050201      0.0        NaN       NaN           NaN\n",
      "1     603.0  164.481351     16.0  35.568851  8.149867  7.180352e-18\n",
      "\n",
      "Baseline pearson (0.3455393549529829, 6.926441774403982e-05)\n",
      "Life Events pearson (0.10890120526473099, 0.22293974870293615)\n",
      "All Variables pearson (0.36324173515787683, 2.7006480237832376e-05)\n",
      "\n",
      "---------SURVEY---------\n",
      "Baseline R-square adj 0.2591922150255461\n",
      "Life Events R-square adj 0.05529154310420059\n",
      "All Variables R-square adj 0.28160182179527915\n",
      "\n",
      "   df_resid          ssr  df_diff     ss_diff           F  Pr(>F)\n",
      "0    6729.0  2227.130167      0.0         NaN         NaN     NaN\n",
      "1    6733.0  2841.815981     -4.0 -614.685814  364.087578     NaN\n",
      "   df_resid          ssr  df_diff    ss_diff          F        Pr(>F)\n",
      "0    6729.0  2227.130167      0.0        NaN        NaN           NaN\n",
      "1    6717.0  2155.907410     12.0  71.222757  18.491953  4.906698e-40\n",
      "   df_resid          ssr  df_diff     ss_diff           F  Pr(>F)\n",
      "0    6733.0  2841.815981      0.0         NaN         NaN     NaN\n",
      "1    6717.0  2155.907410     16.0  685.908571  133.564638     0.0\n",
      "\n",
      "Baseline pearson (0.5302016267376319, 1.0016313315302405e-98)\n",
      "Life Events pearson (0.26987519558469075, 5.840324518493813e-24)\n",
      "All Variables pearson (0.553246590784659, 4.316713312257456e-109)\n",
      "\n",
      "---------SOCIAL MEDIA + SURVEY---------\n",
      "Baseline R-square adj 0.3571704828818367\n",
      "Life Events R-square adj 0.28038341507883924\n",
      "All Variables R-square adj 0.5033093843631865\n",
      "\n",
      "   df_resid        ssr  df_diff  ss_diff         F  Pr(>F)\n",
      "0     131.0  46.631013      0.0      NaN       NaN     NaN\n",
      "1     125.0  49.810273      6.0 -3.17926 -1.329737     1.0\n",
      "   df_resid        ssr  df_diff    ss_diff         F    Pr(>F)\n",
      "0     131.0  46.631013      0.0        NaN       NaN       NaN\n",
      "1     109.0  29.979211     22.0  16.651802  2.751977  0.000281\n",
      "   df_resid        ssr  df_diff    ss_diff         F        Pr(>F)\n",
      "0     125.0  49.810273      0.0        NaN       NaN           NaN\n",
      "1     109.0  29.979211     16.0  19.831062  4.506426  8.655522e-07\n",
      "\n",
      "Baseline pearson (0.4398051095902894, 0.015017827204699989)\n",
      "Life Events pearson (0.40633563774352666, 0.025870534319203116)\n",
      "All Variables pearson (0.520380979399897, 0.003199355012966243)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_all_regression('anxiety', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7da27f9a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------SOCIAL MEDIA + SURVEY---------\n",
      "Baseline R-square adj 0.24437320723951328\n",
      "Life Events R-square adj 0.06283115238978265\n",
      "All Variables R-square adj 0.2745631707396997\n",
      "\n",
      "   df_resid          ssr  df_diff     ss_diff           F  Pr(>F)\n",
      "0    7296.0  2427.075649      0.0         NaN         NaN     NaN\n",
      "1    7299.0  3011.427046     -3.0 -584.351397  472.110706     NaN\n",
      "   df_resid          ssr  df_diff     ss_diff          F        Pr(>F)\n",
      "0    7296.0  2427.075649      0.0         NaN        NaN           NaN\n",
      "1    7282.0  2325.634246     14.0  101.441404  22.688014  5.557028e-58\n",
      "   df_resid          ssr  df_diff   ss_diff           F  Pr(>F)\n",
      "0    7299.0  3011.427046      0.0       NaN         NaN     NaN\n",
      "1    7282.0  2325.634246     17.0  685.7928  126.314516     0.0\n",
      "\n",
      "Baseline pearson (0.5110938369211977, 3.646142742973813e-98)\n",
      "Life Events pearson (0.2677242857743038, 1.961243299780616e-25)\n",
      "All Variables pearson (0.536659938372349, 6.668266538579121e-110)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_stacked_regression('anxiety')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b4f591e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stress_level(row):\n",
    "    if row['stress'] >= 4.0:\n",
    "        return 'High'\n",
    "    elif row['stress'] <= 2.0:\n",
    "        return 'Low'\n",
    "    else:\n",
    "        return 'Medium'\n",
    "    \n",
    "def sleep_level(row):\n",
    "    if row['sleep'] >= 8.0:\n",
    "        return 'High'\n",
    "    elif row['sleep'] <= 4.0:\n",
    "        return 'Low'\n",
    "    else:\n",
    "        return 'Medium'\n",
    "    \n",
    "def anxiety_level(row):\n",
    "    if row['anxiety'] >= 3.0:\n",
    "        return 'High'\n",
    "    elif row['anxiety'] <= 2.0:\n",
    "        return 'Low'\n",
    "    else:\n",
    "        return 'Medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "cfc14098",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_social_media_data = pd.read_csv('data/Superimposed/Facebook Data For Life Events-Combined - FB Data.csv')\n",
    "df_social_media_data = df_social_media_data[['snapshot_id', 'created_time', 'Text', 'final_life_event_category_2', 'ended/ongoing']]\n",
    "df_social_media_data = df_social_media_data.replace({'PostiveMove':'PositiveMove', 'Negative Move':'NegativeMove'})\n",
    "df_social_media_data = df_social_media_data.drop(df_social_media_data[((df_social_media_data['final_life_event_category_2'].isnull() == True))].index)\n",
    "df_social_media_data['created_date'] = pd.to_datetime(df_social_media_data['created_time'], format = '%Y-%m-%d %H:%M:%S').dt.date\n",
    "df_social_media_data['valence'] = df_social_media_data.apply(compute_sentiment, axis=1)\n",
    "df_social_media_data['day'] = df_social_media_data['created_date']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "a95a3de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snapshot_id</th>\n",
       "      <th>created_time</th>\n",
       "      <th>Text</th>\n",
       "      <th>final_life_event_category_2</th>\n",
       "      <th>ended/ongoing</th>\n",
       "      <th>created_date</th>\n",
       "      <th>valence</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>12840161237957324034</td>\n",
       "      <td>2018-03-17 10:23:39</td>\n",
       "      <td>Dinner on the airplane, Bibimbap! Oh and by th...</td>\n",
       "      <td>Vacation</td>\n",
       "      <td>ongoing</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               snapshot_id         created_time  \\\n",
       "1912  12840161237957324034  2018-03-17 10:23:39   \n",
       "\n",
       "                                                   Text  \\\n",
       "1912  Dinner on the airplane, Bibimbap! Oh and by th...   \n",
       "\n",
       "     final_life_event_category_2 ended/ongoing created_date  valence  \\\n",
       "1912                    Vacation       ongoing   2018-03-17        0   \n",
       "\n",
       "             day  \n",
       "1912  2018-03-17  "
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_social_media_data[df_social_media_data['Text'] == 'Dinner on the airplane, Bibimbap! Oh and by the way....we arrived to Seoul!']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "a69c960e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snapshot_id</th>\n",
       "      <th>Text</th>\n",
       "      <th>day</th>\n",
       "      <th>stress</th>\n",
       "      <th>sleep</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>stress_imputed</th>\n",
       "      <th>sleep_imputed</th>\n",
       "      <th>anxiety_imputed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>9251084965720942673</td>\n",
       "      <td>This guy will be missed.  Will always wish we ...</td>\n",
       "      <td>2018-10-07</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>9252537403715547191</td>\n",
       "      <td>Family reunion</td>\n",
       "      <td>2018-06-10</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>9252537403715547191</td>\n",
       "      <td>Oh Zurich, you are so beautiful. I should visi...</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>9252537403715547191</td>\n",
       "      <td>From Poland with love! Happy 4th of July to al...</td>\n",
       "      <td>2018-07-04</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>9252537403715547191</td>\n",
       "      <td>Spontaneously available for activities in DC d...</td>\n",
       "      <td>2018-08-03</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>13713449702891591320</td>\n",
       "      <td>What a beautiful weekend we had celebrating ou...</td>\n",
       "      <td>2018-08-06</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>13721933279774980118</td>\n",
       "      <td>#chicagothistime #friends #vacationmode #chica...</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>13725566228858842118</td>\n",
       "      <td>Thank you, Aspen for the fresh snow and great ...</td>\n",
       "      <td>2018-12-02</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>13804268872491564932</td>\n",
       "      <td>Ate, drank, and surfed our way through Central...</td>\n",
       "      <td>2018-11-23</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>13804268872491564932</td>\n",
       "      <td>It’s a wrap. Thanks for hosting us, Torres del...</td>\n",
       "      <td>2018-11-23</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1975 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               snapshot_id                                               Text  \\\n",
       "1890   9251084965720942673  This guy will be missed.  Will always wish we ...   \n",
       "1131   9252537403715547191                                     Family reunion   \n",
       "1132   9252537403715547191  Oh Zurich, you are so beautiful. I should visi...   \n",
       "1133   9252537403715547191  From Poland with love! Happy 4th of July to al...   \n",
       "1134   9252537403715547191  Spontaneously available for activities in DC d...   \n",
       "...                    ...                                                ...   \n",
       "506   13713449702891591320  What a beautiful weekend we had celebrating ou...   \n",
       "583   13721933279774980118  #chicagothistime #friends #vacationmode #chica...   \n",
       "1027  13725566228858842118  Thank you, Aspen for the fresh snow and great ...   \n",
       "151   13804268872491564932  Ate, drank, and surfed our way through Central...   \n",
       "152   13804268872491564932  It’s a wrap. Thanks for hosting us, Torres del...   \n",
       "\n",
       "             day    stress     sleep   anxiety  stress_imputed  sleep_imputed  \\\n",
       "1890  2018-10-07  2.666667  9.000000  2.166667            True           True   \n",
       "1131  2018-06-10  1.600000  7.500000  1.000000           False          False   \n",
       "1132  2018-07-01  1.333333  7.000000  1.400000           False          False   \n",
       "1133  2018-07-04  1.800000  7.666667  1.366667            True           True   \n",
       "1134  2018-08-03  1.800000  7.500000  1.400000           False          False   \n",
       "...          ...       ...       ...       ...             ...            ...   \n",
       "506   2018-08-06  2.000000  5.000000  1.500000            True           True   \n",
       "583   2018-07-01  2.250000  7.000000  2.250000           False          False   \n",
       "1027  2018-12-02  1.333333  9.000000  1.000000            True           True   \n",
       "151   2018-11-23  1.400000  7.000000  1.750000            True           True   \n",
       "152   2018-11-23  1.400000  7.000000  1.750000            True           True   \n",
       "\n",
       "      anxiety_imputed  \n",
       "1890             True  \n",
       "1131            False  \n",
       "1132            False  \n",
       "1133             True  \n",
       "1134            False  \n",
       "...               ...  \n",
       "506              True  \n",
       "583             False  \n",
       "1027             True  \n",
       "151              True  \n",
       "152              True  \n",
       "\n",
       "[1975 rows x 9 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dailies = calculate_avg_mental_health()\n",
    "df_demographics = load_demographics_data()\n",
    "median_per_individual = df_dailies.groupby(['snapshot_id']).median().reset_index()[['snapshot_id','stress', 'sleep', 'anxiety']]\n",
    "\n",
    "merged_data = pd.merge(df_dailies, df_demographics, how=\"inner\", on=\"snapshot_id\")\n",
    "merged_data_sm = pd.merge(merged_data, df_social_media_data, how=\"right\", on=[\"snapshot_id\", \"day\"])\n",
    "\n",
    "\n",
    "merged_data_sm['stress_imputed'] = False\n",
    "merged_data_sm['sleep_imputed'] = False\n",
    "merged_data_sm['anxiety_imputed'] = False\n",
    "\n",
    "for i, row in merged_data_sm.iterrows():\n",
    "    if row['stress'] != row['stress']:\n",
    "        merged_data_sm._set_value(i,'stress',median_per_individual[median_per_individual['snapshot_id'] == row['snapshot_id']]['stress'].values[0])\n",
    "        merged_data_sm._set_value(i,'stress_imputed', True)\n",
    "    if row['sleep'] != row['sleep']:\n",
    "        merged_data_sm._set_value(i,'sleep',median_per_individual[median_per_individual['snapshot_id'] == row['snapshot_id']]['sleep'].values[0])\n",
    "        merged_data_sm._set_value(i,'sleep_imputed', True)\n",
    "    if row['anxiety'] != row['anxiety']:\n",
    "        merged_data_sm._set_value(i,'anxiety',median_per_individual[median_per_individual['snapshot_id'] == row['snapshot_id']]['anxiety'].values[0])\n",
    "        merged_data_sm._set_value(i,'anxiety_imputed', True)\n",
    "\n",
    "\n",
    "merged_data_sm = merged_data_sm[['snapshot_id', 'Text', 'day', 'stress', 'sleep', 'anxiety', 'stress_imputed', 'sleep_imputed', 'anxiety_imputed']]\n",
    "# merged_data_sm = merged_data_sm[['snapshot_id', 'Text', 'stress', 'sleep', 'anxiety', 'day']]\n",
    "merged_data_sm = merged_data_sm.sort_values(['snapshot_id', 'day'])\n",
    "merged_data_sm.to_csv('Linear Regression/Relative Week/social_media_post_mental_health_labels.csv')\n",
    "merged_data_sm\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
