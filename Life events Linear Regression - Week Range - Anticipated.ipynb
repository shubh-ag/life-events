{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "10482a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (0.12.2)\n",
      "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.19.5)\n",
      "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->statsmodels) (2021.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5->statsmodels) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: vaderSentiment in /home/sagarwal420/.local/lib/python3.6/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vaderSentiment) (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->vaderSentiment) (1.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->vaderSentiment) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->vaderSentiment) (2018.1.18)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2.0.6)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (6.0.7)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert) (4.8.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.5.4)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.5.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (1.5.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (4.3.3)\n",
      "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (3.0.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.1.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.3)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (2.10.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.8.4)\n",
      "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (5.1.3)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.7.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert) (2.0.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.5 in /usr/local/lib/python3.6/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert) (7.0.3)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.6/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert) (1.5.1)\n",
      "Requirement already satisfied: async-generator in /usr/local/lib/python3.6/dist-packages (from nbclient<0.6.0,>=0.5.0->nbconvert) (1.10)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert) (2.8.2)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert) (22.3.0)\n",
      "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert) (6.1)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (58.1.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (1.15.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/lib/python3/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (17.4.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (4.8.1)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert) (5.1.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert) (21.0)\n",
      "Requirement already satisfied: webencodings in /usr/lib/python3/dist-packages (from bleach->nbconvert) (0.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert) (2.4.7)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tabulate in /home/sagarwal420/.local/lib/python3.6/site-packages (0.8.10)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.19.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install statsmodels\n",
    "!pip3 install vaderSentiment\n",
    "!pip3 install nbconvert\n",
    "!pip3 install tabulate\n",
    "!pip3 install --upgrade scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "bc4ee099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "from statistics import mean\n",
    "\n",
    "from datetime import date, timedelta\n",
    "import datetime\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.gof import chisquare as chisquare\n",
    "import vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "import csv\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "b39d1d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.datetime.strptime(\"2020-08-22\", \"%Y-%m-%d\").date()\n",
    "\n",
    "def convertToTime(row, columnName):\n",
    "    return datetime.datetime.strptime(row[columnName], \"%Y-%m-%d\").date()\n",
    "\n",
    "def convertToDate(row, columnName):\n",
    "    return datetime.datetime.strptime(row[columnName], \"%Y-%m-%d %H:%M:%S\").date()\n",
    "    \n",
    "def update_end_date(row, columnName, latestDate):\n",
    "    if row[columnName] == row[columnName]:\n",
    "        return row[columnName]\n",
    "    else:\n",
    "        return latestDate\n",
    "\n",
    "def getDays(row, beginColumnName, endColumnName):\n",
    "    v = datetime.datetime.strptime(str(row[endColumnName]), \"%Y-%m-%d\").date() - datetime.datetime.strptime(row[beginColumnName], \"%Y-%m-%d\").date()\n",
    "    return v.days\n",
    "\n",
    "def calculate_recency(row, columnName):\n",
    "    return (current_date - datetime.datetime.strptime(str(row[columnName]), \"%Y-%m-%d\").date()).days\n",
    "\n",
    "def lookup_index(row, columnName, array):\n",
    "    if(row[columnName] not in array):\n",
    "        return -1\n",
    "    return array.index(row[columnName]) + 1\n",
    "\n",
    "def colour_life_events(row):\n",
    "    colours = {'personal':'lightcoral', 'health':'orange', 'work':'lightgreen', 'financial':'teal', 'weather':'blueviolet', 'societal':'navy','other':'skyblue'}\n",
    "    return colours[row['life_event_type']]\n",
    "\n",
    "def remove_rows(base_df, other_df):\n",
    "    modified_df = other_df.drop(other_df[other_df['snapshot_id'] not in base_df['snapshot_id'].values].index)\n",
    "    return modified_df\n",
    "\n",
    "def fix_signficance(row):\n",
    "    if('significance' in row['valence']):\n",
    "        return row['valence']\n",
    "    else:\n",
    "        return row['significance']\n",
    "\n",
    "def fix_valence(row):\n",
    "    if('significance' in row['significance']):\n",
    "        return row['valence']\n",
    "    else:\n",
    "        return row['significance']  \n",
    "\n",
    "def get_broad_category(row, categories, column_name):\n",
    "    if(row[column_name] in categories):\n",
    "        return categories[row[column_name]]\n",
    "    return \"UNKNOWN\"\n",
    "    \n",
    "def compute_sentiment(row):\n",
    "    post = row['Text']\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    vs = analyzer.polarity_scores(post)\n",
    "    sentiment = 0\n",
    "    if (vs[\"neu\"]>0.8):\n",
    "        sentiment = 0\n",
    "    elif (vs[\"pos\"]==vs[\"neg\"]):\n",
    "        sentiment = 0\n",
    "    elif (vs[\"pos\"]>vs[\"neg\"]):\n",
    "        sentiment = 1\n",
    "    elif (vs[\"neg\"]>vs[\"neu\"]):\n",
    "        sentiment = -1\n",
    "    return sentiment\n",
    "\n",
    "def convert_valence_to_sentiment(row):\n",
    "    valence = row['valence']\n",
    "    retVal = 0\n",
    "    if (valence == 'Neither Positive or Negative'):\n",
    "        retVal = 0\n",
    "    elif(\"Positive\" in valence):\n",
    "        retVal = 1\n",
    "    elif(\"Negative\" in valence):\n",
    "        retVal = -1\n",
    "    return retVal\n",
    "\n",
    "def update_status(row, columnName):\n",
    "    if row[columnName] == row[columnName]:\n",
    "        if \"ongoing\" in row[columnName].lower():\n",
    "            return \"Ongoing\"\n",
    "        return row[columnName]\n",
    "    else:\n",
    "        return \"Ended\"\n",
    "\n",
    "def update_education_level(row, columnName):\n",
    "    if 'college' in row[columnName].lower():\n",
    "        return \"College Degree\"\n",
    "    elif 'doctoral' in row[columnName].lower():\n",
    "        return \"Doctoral Degree\"\n",
    "    elif 'master' in row[columnName].lower() or 'grad' in row[columnName].lower():\n",
    "        return \"Graduate Degree\"\n",
    "    elif 'hs' in row[columnName].lower() or 'high school' in row[columnName].lower():\n",
    "        return \"High School\"\n",
    "    \n",
    "    return row[columnName]\n",
    "\n",
    "def add_avg_dependent_variable(row, weekly_data):\n",
    "    start_date = datetime.datetime.strptime(str(row['UpdatedBeginDate']), \"%Y-%m-%d\").date()\n",
    "    end_date = datetime.datetime.strptime(str(row['UpdatedEndDate']), \"%Y-%m-%d\").date()\n",
    "    year_week = []\n",
    "    delta = timedelta(days=1)\n",
    "    dependent_variable_data = []\n",
    "    while(start_date < end_date):\n",
    "        (year, week) = (start_date.isocalendar()[0], start_date.isocalendar()[1])\n",
    "        if( (year, week) not in year_week):\n",
    "            year_week.append((year, week))\n",
    "            if (year, week) in weekly_data[row['snapshot_id']]:\n",
    "                dependent_variable_data.append(weekly_data[row['snapshot_id']][(year, week)])\n",
    "        start_date = start_date + delta\n",
    "    if(len(dependent_variable_data) > 0):\n",
    "        return mean(dependent_variable_data)\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "\n",
    "def add_avg_date_based_dependent_variable(row, weekly_data):\n",
    "    date = datetime.datetime.strptime(str(row['created_date']), \"%Y-%m-%d\").date()\n",
    "    year, week = (date.isocalendar()[0], date.isocalendar()[1])\n",
    "    \n",
    "    if (year,week) in weekly_data[row['snapshot_id']]:\n",
    "        return weekly_data[row['snapshot_id']][(year, week)]\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "4331d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_variables             = 'shipley_vocab + shipley_abs + openness + conscientiousness + extraversion + agreeableness + neuroticism + pos_affect + neg_affect + stai_trait + education_level + psqi + age + gender'\n",
    "combined_control_variables    = 'shipley_vocab + shipley_abs + openness + conscientiousness + extraversion + agreeableness + neuroticism + pos_affect + neg_affect + stai_trait + education_level + psqi + age + gender + data_type'\n",
    "\n",
    "sr_life_event_variables       = 'Anticipation + LifeEventFamily + valence + recency + status + Intimacy + Scope + significance_label'\n",
    "sm_life_event_variables       = 'Anticipation + LifeEventFamily + valence + recency + status + Intimacy + Scope'\n",
    "combined_life_event_variables = 'Anticipation + LifeEventFamily + valence + recency + status + Intimacy + Scope + data_type'\n",
    "\n",
    "sr_all_variables     = 'shipley_vocab + shipley_abs + openness + conscientiousness + extraversion + agreeableness + neuroticism + pos_affect + neg_affect + stai_trait + education_level + psqi + age + gender + Anticipation + LifeEventFamily + valence + recency + status + Intimacy + Scope + significance_label'\n",
    "sm_all_variables     = 'shipley_vocab + shipley_abs + openness + conscientiousness + extraversion + agreeableness + neuroticism + pos_affect + neg_affect + stai_trait + education_level + psqi + age + gender + Anticipation + LifeEventFamily + valence + recency + status + Intimacy + Scope'\n",
    "combined_all_variables        = 'shipley_vocab + shipley_abs + openness + conscientiousness + extraversion + agreeableness + neuroticism + pos_affect + neg_affect + stai_trait + education_level + psqi + age + gender + Anticipation + LifeEventFamily + valence + recency + status + Intimacy + Scope + data_type'\n",
    "# combined_sm_sr_all_variables  = 'shipley_vocab_sm + shipley_vocab_sr + shipley_abs_sm + shipley_abs_sr + openness_sm + openness_sr + conscientiousness_sm + conscientiousness_sr + extraversion_sm + extraversion_sr + agreeableness_sm + agreeableness_sr + neuroticism_sm + neuroticism_sr + pos_affect_sm + pos_affect_sr + neg_affect_sm + neg_affect_sr + stai_trait_sm + stai_trait_sr + education_level_sm + education_level_sr + psqi_sm + psqi_sr + age_sm + age_sr + gender_sm + gender_sr + Anticipation_sm + Anticipation_sr + LifeEventFamily_sm + LifeEventFamily_sr + valence_sm + valence_sr + Intimacy_sm + Intimacy_sr + Scope_sm + Scope_sr + data_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "bcc9ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_demographics_data():\n",
    "    demographics_data = pd.read_csv('data/igtbs_demographics_complete.csv', parse_dates=True)\n",
    "    demographics_data = demographics_data[['age','gender','snapshot_id', 'shipley.vocab', 'shipley.abs', 'openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism','pos.affect','neg.affect','stai.trait','psqi','educ']]\n",
    "    demographics_data['education_level'] = demographics_data.apply(update_education_level, columnName='educ', axis=1)\n",
    "    demographics_data = demographics_data.drop(columns=['educ'])\n",
    "    demographics_data = demographics_data.rename(columns={\n",
    "        'shipley.vocab': 'shipley_vocab',\n",
    "        'shipley.abs': 'shipley_abs',\n",
    "        'pos.affect': 'pos_affect',\n",
    "        'neg.affect': 'neg_affect',\n",
    "        'stai.trait': 'stai_trait'\n",
    "    })\n",
    "    return demographics_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "4b56901c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>snapshot_id</th>\n",
       "      <th>shipley_vocab</th>\n",
       "      <th>shipley_abs</th>\n",
       "      <th>openness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>extraversion</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>pos_affect</th>\n",
       "      <th>neg_affect</th>\n",
       "      <th>stai_trait</th>\n",
       "      <th>psqi</th>\n",
       "      <th>education_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>11156103277197680506</td>\n",
       "      <td>32.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>38.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>College Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>13346780717560972831</td>\n",
       "      <td>38.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.916667</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>41.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Graduate Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>12932409338132389043</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.916667</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Graduate Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>10385244076367909694</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Graduate Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>10671464268435700062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>College Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>44.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>10033784408945437200</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Graduate Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>51.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>13257691313989387573</td>\n",
       "      <td>34.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Graduate Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>44.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>13370808519384713343</td>\n",
       "      <td>35.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>39.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Graduate Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>31.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>12173290729829297463</td>\n",
       "      <td>32.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.583333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>38.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>College Degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>35.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>9381952670851740549</td>\n",
       "      <td>37.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>College Degree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>754 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  gender           snapshot_id  shipley_vocab  shipley_abs  openness  \\\n",
       "0    39.0  Female  11156103277197680506           32.0         15.0  4.750000   \n",
       "1    39.0  Female  13346780717560972831           38.0         19.0  3.500000   \n",
       "2    25.0  Female  12932409338132389043           32.0         19.0  4.916667   \n",
       "3    33.0    Male  10385244076367909694           34.0         17.0  3.416667   \n",
       "4    37.0  Female  10671464268435700062           39.0         15.0  4.500000   \n",
       "..    ...     ...                   ...            ...          ...       ...   \n",
       "749  44.0    Male  10033784408945437200           34.0         17.0  3.500000   \n",
       "750  51.0    Male  13257691313989387573           34.0         20.0  4.500000   \n",
       "751  44.0  Female  13370808519384713343           35.0         18.0  3.500000   \n",
       "752  31.0  Female  12173290729829297463           32.0         17.0  3.583333   \n",
       "753  35.0    Male   9381952670851740549           37.0         15.0  4.000000   \n",
       "\n",
       "     conscientiousness  extraversion  agreeableness  neuroticism  pos_affect  \\\n",
       "0             4.666667      3.666667       4.416667     2.333333        38.0   \n",
       "1             4.833333      3.000000       4.916667     1.833333        41.0   \n",
       "2             4.083333      3.750000       4.000000     4.083333        20.0   \n",
       "3             2.166667      2.916667       3.000000     2.000000        25.0   \n",
       "4             5.000000      3.916667       3.750000     3.000000        36.0   \n",
       "..                 ...           ...            ...          ...         ...   \n",
       "749           4.250000      2.750000       4.500000     2.166667        30.0   \n",
       "750           2.666667      2.750000       4.250000     2.833333        35.0   \n",
       "751           4.250000      4.333333       3.250000     1.083333        39.0   \n",
       "752           4.666667      2.916667       3.416667     3.166667        38.0   \n",
       "753           4.000000      2.750000       4.333333     3.333333        26.0   \n",
       "\n",
       "     neg_affect  stai_trait  psqi  education_level  \n",
       "0          15.0        39.0   7.0   College Degree  \n",
       "1          16.0        28.0   8.0  Graduate Degree  \n",
       "2          24.0        55.0  10.0  Graduate Degree  \n",
       "3          24.0        51.0   9.0  Graduate Degree  \n",
       "4          16.0        35.0   3.0   College Degree  \n",
       "..          ...         ...   ...              ...  \n",
       "749        13.0        35.0   4.0  Graduate Degree  \n",
       "750        17.0        41.0   5.0  Graduate Degree  \n",
       "751        12.0        25.0   8.0  Graduate Degree  \n",
       "752        18.0        31.0   3.0   College Degree  \n",
       "753        23.0        43.0   6.0   College Degree  \n",
       "\n",
       "[754 rows x 15 columns]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_demographics_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "d8ae65d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_survey_categories():\n",
    "    df_self_reported_categories = pd.read_csv('data/Life Events Categories Mapping - Self-Reported Categories.csv')\n",
    "    return df_self_reported_categories\n",
    "\n",
    "def load_survey_data_without_categories():\n",
    "    df_survey = pd.read_csv('data/Superimposed/LifeEvents_Curated_non_blinded.csv', parse_dates=True)    \n",
    "    df_survey = df_survey[['snapshot_id', 'description','UpdatedBeginDate', 'UpdatedEndDate','life_event_type', 'work_perf_impact', 'significance','valence', 'ended_or_ongoing']]\n",
    "\n",
    "    # Date manipulation\n",
    "    latest_date = max(datetime.datetime.strptime(str(x), \"%Y-%m-%d\").date() if x == x else datetime.date.min for x in df_survey['UpdatedEndDate'])\n",
    "    latest_date = max(latest_date, max(datetime.datetime.strptime(str(x), \"%Y-%m-%d\").date() if x == x else datetime.date.min for x in df_survey['UpdatedBeginDate']))\n",
    "    df_survey = df_survey.drop(df_survey[df_survey['UpdatedBeginDate'].isnull() == True].index)\n",
    "    df_survey['UpdatedEndDate'] = df_survey.apply(update_end_date, columnName='UpdatedEndDate', latestDate=latest_date, axis=1)\n",
    "    df_survey['num_of_days'] = df_survey.apply(getDays, endColumnName='UpdatedEndDate', beginColumnName='UpdatedBeginDate', axis=1)\n",
    "    df_survey['UpdatedBeginDate_time'] = df_survey.apply(convertToTime, columnName='UpdatedBeginDate', axis=1)\n",
    "    df_survey['recency'] = df_survey.apply(calculate_recency, columnName='UpdatedEndDate', axis=1)\n",
    "\n",
    "    # Update values for valence and significance\n",
    "    df_survey.replace({'valence': {np.nan: 'Neither Positive or Negative'}, 'significance': {np.nan: 'Neither Positive or Negative'}}, inplace=True)\n",
    "    df_survey['fixed_signficance'] = df_survey.apply(fix_signficance, axis = 1)\n",
    "    df_survey['fixed_valence'] = df_survey.apply(fix_valence, axis = 1)\n",
    "    df_survey = df_survey.drop(columns = ['valence', 'significance'])\n",
    "    df_survey = df_survey.rename(columns={\"fixed_signficance\": \"significance\", \"fixed_valence\": \"valence\"})\n",
    "    df_survey['valence'] = df_survey.apply(convert_valence_to_sentiment, axis=1)\n",
    "    df_survey['ended_or_ongoing'] = df_survey.apply(update_status, columnName='ended_or_ongoing', axis=1)\n",
    "\n",
    "    # Select columns we are interested in\n",
    "    df_survey = df_survey[['snapshot_id', 'description', 'UpdatedBeginDate', 'UpdatedEndDate', 'significance', 'valence', 'ended_or_ongoing', 'recency']]\n",
    "\n",
    "    # Label encoding for significance\n",
    "    le_significance = LabelEncoder()\n",
    "    le_significance.fit(df_survey['significance'].values)\n",
    "    df_survey['significance_label'] = df_survey.apply(lambda x: le_significance.transform([x['significance']])[0], axis=1)\n",
    "    df_survey = df_survey.drop(columns=['significance'])\n",
    "\n",
    "    return df_survey\n",
    "\n",
    "def load_survey_data():\n",
    "    df_survey_without_categories = load_survey_data_without_categories()\n",
    "    df_self_reported_categories = load_survey_categories()\n",
    "    df_survey = pd.merge(df_survey_without_categories, df_self_reported_categories, how=\"inner\", left_on=\"description\", right_on=\"SR_LifeEvent\")\n",
    "    df_survey = df_survey.drop(columns=['description', 'SR_LifeEvent', 'LifeEventFinal', 'LifeEventFamily2'])\n",
    "    df_survey = df_survey.rename(columns={'ended_or_ongoing':'status'})\n",
    "\n",
    "    return df_survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "480efef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_social_media_categories():\n",
    "    df_social_media_categories = pd.read_csv('data/Life Events Categories Mapping - Social Media Categories-2.csv')\n",
    "    return df_social_media_categories\n",
    "\n",
    "def load_social_media_data_without_categories():\n",
    "    df_social_media_data = pd.read_csv('data/Superimposed/Facebook Data For Life Events-Combined - FB Data.csv')\n",
    "    df_social_media_data = df_social_media_data[['snapshot_id', 'created_time', 'Text', 'final_life_event_category_2', 'ended/ongoing']]\n",
    "    df_social_media_data = df_social_media_data.replace({'PostiveMove':'PositiveMove', 'Negative Move':'NegativeMove'})\n",
    "    df_social_media_data = df_social_media_data.drop(df_social_media_data[((df_social_media_data['final_life_event_category_2'].isnull() == True))].index)\n",
    "    df_social_media_data['created_date'] = df_social_media_data.apply(convertToDate, columnName='created_time', axis=1)\n",
    "    df_social_media_data['valence'] = df_social_media_data.apply(compute_sentiment, axis=1)\n",
    "    df_social_media_data = df_social_media_data.drop(columns=['created_time','Text'])\n",
    "    df_social_media_data['recency'] = df_social_media_data.apply(calculate_recency, columnName='created_date', axis=1)\n",
    "    df_social_media_data['ended/ongoing'] = df_social_media_data.apply(update_status, columnName='ended/ongoing', axis=1)\n",
    "    return df_social_media_data\n",
    "\n",
    "def load_social_media_data():\n",
    "    df_social_media_data = load_social_media_data_without_categories()\n",
    "    df_social_media_categories = load_social_media_categories()\n",
    "    df_social_media_data_with_categories = pd.merge(df_social_media_data, df_social_media_categories, how=\"inner\", left_on='final_life_event_category_2', right_on='SM_LifeEvent')\n",
    "    df_social_media_data_with_categories = df_social_media_data_with_categories.drop(columns=['final_life_event_category_2','SM_LifeEvent','LifeEventFamily2','Comments','SignificanceRank'])\n",
    "    df_social_media_data_with_categories = df_social_media_data_with_categories.rename(columns={'ended/ongoing':'status'})\n",
    "    return df_social_media_data_with_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "23e9b793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snapshot_id</th>\n",
       "      <th>status</th>\n",
       "      <th>created_date</th>\n",
       "      <th>valence</th>\n",
       "      <th>recency</th>\n",
       "      <th>LifeEventFamily</th>\n",
       "      <th>Anticipation</th>\n",
       "      <th>Intimacy</th>\n",
       "      <th>Scope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12840161237957324034</td>\n",
       "      <td>Ongoing</td>\n",
       "      <td>2018-03-16</td>\n",
       "      <td>0</td>\n",
       "      <td>890</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Anticipated</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11156103277197680506</td>\n",
       "      <td>Ongoing</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>753</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Anticipated</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11329586216091316598</td>\n",
       "      <td>Ongoing</td>\n",
       "      <td>2018-09-08</td>\n",
       "      <td>0</td>\n",
       "      <td>714</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Anticipated</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13543308681200334026</td>\n",
       "      <td>Ongoing</td>\n",
       "      <td>2018-07-22</td>\n",
       "      <td>0</td>\n",
       "      <td>762</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Anticipated</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12676581714475000627</td>\n",
       "      <td>Ongoing</td>\n",
       "      <td>2018-04-25</td>\n",
       "      <td>0</td>\n",
       "      <td>850</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Anticipated</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>10729524556661174446</td>\n",
       "      <td>Ongoing</td>\n",
       "      <td>2018-12-19</td>\n",
       "      <td>0</td>\n",
       "      <td>612</td>\n",
       "      <td>School</td>\n",
       "      <td>Unanticipated</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>9767765376628075157</td>\n",
       "      <td>Ongoing</td>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>0</td>\n",
       "      <td>757</td>\n",
       "      <td>Health</td>\n",
       "      <td>Anticipated</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>9767765376628075157</td>\n",
       "      <td>Ongoing</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>0</td>\n",
       "      <td>669</td>\n",
       "      <td>Health</td>\n",
       "      <td>Anticipated</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>9767765376628075157</td>\n",
       "      <td>ended</td>\n",
       "      <td>2018-09-19</td>\n",
       "      <td>1</td>\n",
       "      <td>703</td>\n",
       "      <td>Health</td>\n",
       "      <td>Unanticipated</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>13491403714608340181</td>\n",
       "      <td>Ongoing</td>\n",
       "      <td>2018-11-23</td>\n",
       "      <td>0</td>\n",
       "      <td>638</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Anticipated</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1980 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               snapshot_id   status created_date  valence  recency  \\\n",
       "0     12840161237957324034  Ongoing   2018-03-16        0      890   \n",
       "1     11156103277197680506  Ongoing   2018-07-31        1      753   \n",
       "2     11329586216091316598  Ongoing   2018-09-08        0      714   \n",
       "3     13543308681200334026  Ongoing   2018-07-22        0      762   \n",
       "4     12676581714475000627  Ongoing   2018-04-25        0      850   \n",
       "...                    ...      ...          ...      ...      ...   \n",
       "1975  10729524556661174446  Ongoing   2018-12-19        0      612   \n",
       "1976   9767765376628075157  Ongoing   2018-07-27        0      757   \n",
       "1977   9767765376628075157  Ongoing   2018-10-23        0      669   \n",
       "1978   9767765376628075157    ended   2018-09-19        1      703   \n",
       "1979  13491403714608340181  Ongoing   2018-11-23        0      638   \n",
       "\n",
       "     LifeEventFamily   Anticipation  Intimacy  Scope  \n",
       "0           Personal    Anticipated         2      2  \n",
       "1           Personal    Anticipated         2      2  \n",
       "2           Personal    Anticipated         2      2  \n",
       "3           Personal    Anticipated         2      2  \n",
       "4           Personal    Anticipated         2      2  \n",
       "...              ...            ...       ...    ...  \n",
       "1975          School  Unanticipated         3      2  \n",
       "1976          Health    Anticipated         3      3  \n",
       "1977          Health    Anticipated         3      3  \n",
       "1978          Health  Unanticipated         3      3  \n",
       "1979        Personal    Anticipated         2      2  \n",
       "\n",
       "[1980 rows x 9 columns]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_social_media_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "6108bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dailies_data():\n",
    "    df_dailies = pd.read_csv('data/Superimposed/dailies_scores.csv', low_memory=False)\n",
    "    df_dailies = df_dailies[['snapshot_id','day', 'alc_status', 'alc.quantity.d', 'anxiety.d', 'pos.affect.d', 'neg.affect.d','sleep.d', 'stress.d']]\n",
    "    df_dailies['day_time'] = df_dailies.apply(convertToTime, columnName='day', axis=1)\n",
    "    df_dailies = df_dailies.rename(columns={'alc.quantity.d': 'alc_quantity',\n",
    "    'anxiety.d': 'anxiety',\n",
    "    'pos.affect.d': 'pos_affect',\n",
    "    'neg.affect.d': 'neg_affect',\n",
    "    'sleep.d': 'sleep',\n",
    "    'stress.d': 'stress'})\n",
    "    df_dailies['sleep'] = df_dailies['sleep'] + 1\n",
    "    return df_dailies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "c618e02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snapshot_id</th>\n",
       "      <th>day</th>\n",
       "      <th>alc_status</th>\n",
       "      <th>alc_quantity</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>pos_affect</th>\n",
       "      <th>neg_affect</th>\n",
       "      <th>sleep</th>\n",
       "      <th>stress</th>\n",
       "      <th>day_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10003528337325499062</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10003528337325499062</td>\n",
       "      <td>2018-03-02</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-03-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003528337325499062</td>\n",
       "      <td>2018-03-04</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003528337325499062</td>\n",
       "      <td>2018-03-06</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-03-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003528337325499062</td>\n",
       "      <td>2018-03-09</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38592</th>\n",
       "      <td>9999689421615292586</td>\n",
       "      <td>2018-06-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38593</th>\n",
       "      <td>9999689421615292586</td>\n",
       "      <td>2018-06-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38594</th>\n",
       "      <td>9999689421615292586</td>\n",
       "      <td>2018-06-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38595</th>\n",
       "      <td>9999689421615292586</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38596</th>\n",
       "      <td>9999689421615292586</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-07-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38597 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                snapshot_id         day alc_status  alc_quantity  anxiety  \\\n",
       "0      10003528337325499062  2018-03-01        yes           3.0      2.0   \n",
       "1      10003528337325499062  2018-03-02         no           0.0      2.0   \n",
       "2      10003528337325499062  2018-03-04         no           0.0      1.0   \n",
       "3      10003528337325499062  2018-03-06         no           0.0      1.0   \n",
       "4      10003528337325499062  2018-03-09         no           0.0      2.0   \n",
       "...                     ...         ...        ...           ...      ...   \n",
       "38592   9999689421615292586  2018-06-23        NaN           NaN      1.0   \n",
       "38593   9999689421615292586  2018-06-25        NaN           NaN      1.0   \n",
       "38594   9999689421615292586  2018-06-28        NaN           NaN      2.0   \n",
       "38595   9999689421615292586  2018-06-30        NaN           NaN      1.0   \n",
       "38596   9999689421615292586  2018-07-01        NaN           NaN      1.0   \n",
       "\n",
       "       pos_affect  neg_affect  sleep  stress    day_time  \n",
       "0            11.0         6.0    6.0     2.0  2018-03-01  \n",
       "1            13.0         5.0    8.0     2.0  2018-03-02  \n",
       "2             5.0         5.0    9.0     1.0  2018-03-04  \n",
       "3            15.0         5.0    8.0     1.0  2018-03-06  \n",
       "4            11.0         5.0    8.0     1.0  2018-03-09  \n",
       "...           ...         ...    ...     ...         ...  \n",
       "38592         8.0         5.0    NaN     1.0  2018-06-23  \n",
       "38593         5.0         5.0    NaN     1.0  2018-06-25  \n",
       "38594        12.0         5.0    NaN     2.0  2018-06-28  \n",
       "38595         8.0         5.0    NaN     1.0  2018-06-30  \n",
       "38596         9.0         5.0    NaN     1.0  2018-07-01  \n",
       "\n",
       "[38597 rows x 10 columns]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dailies_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "ba6eae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_values(df_dailies, merged_data, start_date_column, dependent_variable):\n",
    "    snapshot_id_day_value = {}\n",
    "    for index, row in df_dailies.iterrows():\n",
    "        if row['snapshot_id'] not in snapshot_id_day_value:\n",
    "            snapshot_id_day_value[row['snapshot_id']] = {}\n",
    "        snapshot_id_day_value[row['snapshot_id']][str(row['day'])] = row[dependent_variable]\n",
    "\n",
    "    merged_data[dependent_variable] = -1\n",
    "    delta_5 = timedelta(days=5)\n",
    "    delta_3 = timedelta(days=3)\n",
    "    delta_7 = timedelta(days=7)\n",
    "    one_day = timedelta(days=1)\n",
    "    week_avg = []\n",
    "    for index, row in merged_data.iterrows():\n",
    "        if row['snapshot_id'] in snapshot_id_day_value:\n",
    "            if row['Anticipation'] == 'Anticipated':\n",
    "                start_date = datetime.datetime.strptime(str(row[start_date_column]), \"%Y-%m-%d\").date() - delta_7\n",
    "                end_date = datetime.datetime.strptime(str(row[start_date_column]), \"%Y-%m-%d\").date() + delta_5\n",
    "            else:\n",
    "                start_date = datetime.datetime.strptime(str(row[start_date_column]), \"%Y-%m-%d\").date() - delta_5\n",
    "                end_date = datetime.datetime.strptime(str(row[start_date_column]), \"%Y-%m-%d\").date() + delta_7\n",
    "            value = 0\n",
    "            count = 0\n",
    "            while start_date <= end_date:\n",
    "                if (str(start_date) in snapshot_id_day_value[row['snapshot_id']]):\n",
    "                    if snapshot_id_day_value[row['snapshot_id']][str(start_date)] == snapshot_id_day_value[row['snapshot_id']][str(start_date)]:\n",
    "                        value+=snapshot_id_day_value[row['snapshot_id']][str(start_date)]\n",
    "                        count+=1\n",
    "                start_date+=one_day\n",
    "            if count > 0:\n",
    "                row[dependent_variable] = round(value / count, 3)\n",
    "                week_avg.append(row.copy(deep=True))\n",
    "    return week_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "c17a4fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df_for_regression_baseline(dependent_variable):\n",
    "    try:\n",
    "        merged_data = pd.read_csv('Linear Regression/WeekRangeAnticipated/baseline_regression_'+dependent_variable+'.csv')\n",
    "    except:\n",
    "        df_demographics = load_demographics_data()\n",
    "        df_dailies = load_dailies_data()\n",
    "        \n",
    "        snapshot_id_day_value = {}\n",
    "        for index, row in df_dailies.iterrows():\n",
    "            if row[dependent_variable] != row[dependent_variable]:\n",
    "                continue\n",
    "            if row['snapshot_id'] not in snapshot_id_day_value:\n",
    "                snapshot_id_day_value[row['snapshot_id']] = {}\n",
    "            snapshot_id_day_value[row['snapshot_id']][str(row['day'])] = row[dependent_variable]\n",
    "            \n",
    "        df_dailies = df_dailies[[dependent_variable, 'day', 'snapshot_id']]\n",
    "        merged_data = pd.merge(df_dailies, df_demographics, how=\"inner\", on=[\"snapshot_id\"])\n",
    "\n",
    "        week_avg = []\n",
    "        merged_data[dependent_variable] = -1\n",
    "        before_delta = timedelta(days=7)\n",
    "        delta = timedelta(days=7)\n",
    "        one_day = timedelta(days=1)\n",
    "        \n",
    "        for index, row in merged_data.iterrows():\n",
    "            if row['snapshot_id'] in snapshot_id_day_value:\n",
    "\n",
    "                start_date = datetime.datetime.strptime(str(row['day']), \"%Y-%m-%d\").date() - before_delta\n",
    "                end_date = datetime.datetime.strptime(str(row['day']), \"%Y-%m-%d\").date() + delta\n",
    "                value = 0\n",
    "                count = 0\n",
    "                while start_date <= end_date:\n",
    "                    if (str(start_date) in snapshot_id_day_value[row['snapshot_id']]):\n",
    "                        value+=snapshot_id_day_value[row['snapshot_id']][str(start_date)]\n",
    "                        count+=1\n",
    "                    start_date+=one_day\n",
    "\n",
    "                if count > 0:\n",
    "                    row[dependent_variable] = round(value / count, 3)\n",
    "                    week_avg.append(row.copy(deep=True))\n",
    "\n",
    "        merged_data = pd.DataFrame(week_avg, columns=merged_data.columns)\n",
    "        merged_data.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        merged_data.to_csv('Linear Regression/WeekRangeAnticipated/baseline_regression_'+dependent_variable+'.csv', index=False)\n",
    "\n",
    "    merged_data = merged_data.drop(columns=['day', 'snapshot_id'])\n",
    "    merged_data = merged_data.dropna()\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "814fa867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df_for_regression_survey_average_weekly(dependent_variable):\n",
    "    try:\n",
    "        merged_data = pd.read_csv('Linear Regression/WeekRangeAnticipated/linear_regression_survey_weekly_'+dependent_variable+'.csv')\n",
    "    except:\n",
    "        df_survey = load_survey_data()\n",
    "        df_demographics = load_demographics_data()\n",
    "        df_dailies = load_dailies_data()\n",
    "        merged_data = pd.merge(df_survey, df_demographics, how=\"inner\", on=[\"snapshot_id\"])\n",
    "\n",
    "        week_avg = get_average_values(df_dailies, merged_data, 'UpdatedBeginDate', dependent_variable)\n",
    "\n",
    "        merged_data = pd.DataFrame(week_avg, columns=merged_data.columns)\n",
    "        merged_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        merged_data.to_csv('Linear Regression/WeekRangeAnticipated/linear_regression_survey_weekly_'+dependent_variable+'.csv', index=False)\n",
    "    merged_data = merged_data.drop(merged_data[merged_data['education_level'] == 'High School'].index)   \n",
    "    merged_data = merged_data.drop(merged_data[merged_data['LifeEventFamily'] == 'School'].index)\n",
    "\n",
    "    merged_data = merged_data.drop(columns=[ 'UpdatedBeginDate', 'UpdatedEndDate', 'snapshot_id'])\n",
    "    merged_data = merged_data.dropna()\n",
    "        \n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "dc1ffd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df_for_regression_social_media_average_weekly(dependent_variable):\n",
    "    try:\n",
    "        merged_data = pd.read_csv('Linear Regression/WeekRangeAnticipated/linear_regression_social_media_weekly_'+dependent_variable+'.csv')\n",
    "    except:\n",
    "        df_social_media = load_social_media_data()\n",
    "        df_demographics = load_demographics_data()\n",
    "        df_dailies = load_dailies_data()\n",
    "        merged_data = pd.merge(df_social_media, df_demographics, how=\"inner\", on=[\"snapshot_id\"])\n",
    "        \n",
    "        week_avg = get_average_values(df_dailies, merged_data, 'created_date', dependent_variable)\n",
    "\n",
    "        merged_data = pd.DataFrame(week_avg, columns=merged_data.columns)\n",
    "        merged_data.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        merged_data.to_csv('Linear Regression/WeekRangeAnticipated/linear_regression_social_media_weekly_'+dependent_variable+'.csv', index=False)\n",
    "    \n",
    "    merged_data = merged_data.drop(merged_data[merged_data['education_level'] == 'High School'].index)\n",
    "    merged_data = merged_data.drop(merged_data[merged_data['LifeEventFamily'] == 'School'].index)\n",
    "    merged_data = merged_data.drop(columns=['snapshot_id', 'created_date'])\n",
    "    merged_data = merged_data.dropna()\n",
    "        \n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "31c64601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df_for_regression_combined_survey_social_media(dependent_variable):\n",
    "    df_social_media = build_df_for_regression_social_media_average_weekly(dependent_variable)\n",
    "    df_social_media['data_type'] = 'Social Media'\n",
    "\n",
    "    df_survey = build_df_for_regression_survey_average_weekly(dependent_variable)\n",
    "    df_survey['data_type'] = 'Survey'\n",
    "    df_survey = df_survey.drop(columns=['significance_label'])\n",
    "\n",
    "    X_input = pd.concat([df_survey, df_social_media])\n",
    "    X_input = X_input.dropna()\n",
    "    return X_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "016d1ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(X_train, dependent_variable, formula):\n",
    "    mod = smf.ols(formula=dependent_variable+'~'+formula, data=X_train)\n",
    "    res = mod.fit()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e9205",
   "metadata": {},
   "source": [
    "## Run Regression  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "b458505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_control_variables(dependent_variable, split=0):\n",
    "    X_input = build_df_for_regression_baseline(dependent_variable)\n",
    "\n",
    "    if split == 0:\n",
    "        return regression(X_input, dependent_variable, control_variables)\n",
    "    else:\n",
    "        X_train, X_test = train_test_split(X_input, test_size=split, random_state=85)\n",
    "        model = regression(X_train, dependent_variable, control_variables)\n",
    "        return X_test, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "49266b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def life_event_variables_all_data(dependent_variable, split=0):\n",
    "    X_input = build_df_for_regression_combined_survey_social_media(dependent_variable)\n",
    "    \n",
    "    if split == 0:\n",
    "        return regression(X_input, dependent_variable, combined_life_event_variables)\n",
    "    else:\n",
    "        X_train, X_test = train_test_split(X_input, test_size=split, random_state=85)\n",
    "        model = regression(X_train, dependent_variable, combined_life_event_variables)\n",
    "        return X_test, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "d605240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def life_event_variables_sr(dependent_variable, split=0):\n",
    "    X_input = build_df_for_regression_survey_average_weekly(dependent_variable)\n",
    "\n",
    "    if split == 0:\n",
    "        return regression(X_input, dependent_variable, sr_life_event_variables)\n",
    "    else:\n",
    "        X_train, X_test = train_test_split(X_input, test_size=split, random_state=85)\n",
    "        model = regression(X_train, dependent_variable, sr_life_event_variables)\n",
    "        return X_test, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "4db194f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def life_event_variables_sm(dependent_variable, split=0):\n",
    "    X_input = build_df_for_regression_social_media_average_weekly(dependent_variable)\n",
    "\n",
    "    if split == 0:\n",
    "        return regression(X_input, dependent_variable, sm_life_event_variables)\n",
    "    else:\n",
    "        X_train, X_test = train_test_split(X_input, test_size=split, random_state=85)\n",
    "        model = regression(X_train, dependent_variable, sm_life_event_variables)\n",
    "        return X_test, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "5f8d3a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_variables_all_data(dependent_variable, split=0):\n",
    "    X_input = build_df_for_regression_combined_survey_social_media(dependent_variable)\n",
    "\n",
    "    if split == 0:\n",
    "        return regression(X_input, dependent_variable, combined_all_variables)\n",
    "    else:\n",
    "        X_train, X_test = train_test_split(X_input, test_size=split, random_state=85)\n",
    "        model = regression(X_train, dependent_variable, combined_all_variables)\n",
    "        return X_test, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "6f9171c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_variables_sr(dependent_variable, split=0):\n",
    "    X_input = build_df_for_regression_survey_average_weekly(dependent_variable)\n",
    "\n",
    "    if split == 0:\n",
    "        return regression(X_input, dependent_variable, sr_all_variables)\n",
    "    else:\n",
    "        X_train, X_test = train_test_split(X_input, test_size=split, random_state=85)\n",
    "        model = regression(X_train, dependent_variable, sr_all_variables)\n",
    "        return X_test, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "bdca8bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_variables_sm(dependent_variable, split=0):\n",
    "    X_input = build_df_for_regression_social_media_average_weekly(dependent_variable)\n",
    "\n",
    "    if split == 0:\n",
    "        return regression(X_input, dependent_variable, sm_all_variables)\n",
    "    else:\n",
    "        X_train, X_test = train_test_split(X_input, test_size=split, random_state=85)\n",
    "        model = regression(X_train, dependent_variable, sm_all_variables)\n",
    "        return X_test, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a61fb9b",
   "metadata": {},
   "source": [
    "# Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "6f540bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_baseline_fn(fn, dependent_variable):\n",
    "    model = fn(dependent_variable)\n",
    "    dataset, train_model = fn(dependent_variable, 0.20)\n",
    "\n",
    "    f_obs = train_model.predict(dataset).values\n",
    "    f_exp = dataset[dependent_variable].values\n",
    "\n",
    "    pearson = scipy.stats.pearsonr(f_obs, f_exp)\n",
    "    return model, [round(model.rsquared_adj, 3), round(pearson[0], 3), \"-\", \"-\"]\n",
    "\n",
    "def run_regression_fn(baseline, fn, dependent_variable):\n",
    "    model = fn(dependent_variable)\n",
    "\n",
    "    dataset, train_model = fn(dependent_variable, 0.20)\n",
    "\n",
    "    f_obs = train_model.predict(dataset).values\n",
    "    f_exp = dataset[dependent_variable].values\n",
    "\n",
    "    pearson = scipy.stats.pearsonr(f_obs, f_exp)\n",
    "    variance = anova_lm(baseline, model)\n",
    "    return [round(model.rsquared_adj, 3), round(pearson[0], 3), round(variance.F.values[-1], 3), round(variance['Pr(>F)'].values[-1], 3)]\n",
    "\n",
    "\n",
    "def run_all_regression(dependent_variable):\n",
    "    data = []\n",
    "    baseline_model, results = run_baseline_fn(baseline_control_variables, dependent_variable)\n",
    "    data.append([\"Dailies\", \"Control\"] + results)\n",
    "    \n",
    "    data.append([\"Social Media + Survey\", \"Life Event\"] + run_regression_fn(baseline_model, life_event_variables_all_data, dependent_variable))\n",
    "    data.append([\"Social Media + Survey\", \"Control + Life Event\"] + run_regression_fn(baseline_model, all_variables_all_data, dependent_variable))\n",
    "    \n",
    "    data.append([\"Social Media\", \"Life Event\"] + run_regression_fn(baseline_model, life_event_variables_sm, dependent_variable))\n",
    "    data.append([\"Social Media\", \"Control + Life Event\"] + run_regression_fn(baseline_model, all_variables_sm, dependent_variable))\n",
    "\n",
    "    data.append([\"Survey\", \"Life Event\"] + run_regression_fn(baseline_model, life_event_variables_sr, dependent_variable))\n",
    "    data.append([\"Survey\", \"Control + Life Event\"] + run_regression_fn(baseline_model, all_variables_sr, dependent_variable))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509fe27f",
   "metadata": {},
   "source": [
    "### STRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "3e65b24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Variables</th>\n",
       "      <th>Adjusted R-square</th>\n",
       "      <th>Pearson Correlation</th>\n",
       "      <th>F-statistic</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dailies</td>\n",
       "      <td>Control</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.438</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Social Media + Survey</td>\n",
       "      <td>Life Event</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.791</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Social Media + Survey</td>\n",
       "      <td>Control + Life Event</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Social Media</td>\n",
       "      <td>Life Event</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.798</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Social Media</td>\n",
       "      <td>Control + Life Event</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Survey</td>\n",
       "      <td>Life Event</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Survey</td>\n",
       "      <td>Control + Life Event</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.129</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dataset             Variables  Adjusted R-square  \\\n",
       "0                Dailies               Control              0.180   \n",
       "1  Social Media + Survey            Life Event              0.067   \n",
       "2  Social Media + Survey  Control + Life Event              0.210   \n",
       "3           Social Media            Life Event              0.077   \n",
       "4           Social Media  Control + Life Event              0.223   \n",
       "5                 Survey            Life Event              0.004   \n",
       "6                 Survey  Control + Life Event              0.262   \n",
       "\n",
       "   Pearson Correlation F-statistic P-value  \n",
       "0                0.438           -       -  \n",
       "1                0.257       0.791       1  \n",
       "2                0.434       0.938   0.903  \n",
       "3                0.282       0.798       1  \n",
       "4                0.483       0.952   0.816  \n",
       "5                0.056       0.765   0.994  \n",
       "6                0.129       1.034   0.406  "
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = run_all_regression('stress')\n",
    "regression_results = pd.DataFrame(d, columns=[\"Dataset\", \"Variables\", \"Adjusted R-square\", \"Pearson Correlation\", \"F-statistic\", \"P-value\"])\n",
    "regression_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0672858a",
   "metadata": {},
   "source": [
    "### SLEEP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "722290ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Variables</th>\n",
       "      <th>Adjusted R-square</th>\n",
       "      <th>Pearson Correlation</th>\n",
       "      <th>F-statistic</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dailies</td>\n",
       "      <td>Control</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.272</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Social Media + Survey</td>\n",
       "      <td>Life Event</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.486</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Social Media + Survey</td>\n",
       "      <td>Control + Life Event</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Social Media</td>\n",
       "      <td>Life Event</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.472</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Social Media</td>\n",
       "      <td>Control + Life Event</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.553</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Survey</td>\n",
       "      <td>Life Event</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.557</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Survey</td>\n",
       "      <td>Control + Life Event</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dataset             Variables  Adjusted R-square  \\\n",
       "0                Dailies               Control              0.078   \n",
       "1  Social Media + Survey            Life Event              0.003   \n",
       "2  Social Media + Survey  Control + Life Event              0.108   \n",
       "3           Social Media            Life Event              0.002   \n",
       "4           Social Media  Control + Life Event              0.144   \n",
       "5                 Survey            Life Event             -0.003   \n",
       "6                 Survey  Control + Life Event              0.117   \n",
       "\n",
       "   Pearson Correlation F-statistic P-value  \n",
       "0                0.272           -       -  \n",
       "1                0.072       0.486       1  \n",
       "2                0.316       0.546       1  \n",
       "3                0.244       0.472       1  \n",
       "4                0.411       0.553       1  \n",
       "5                0.003       0.557       1  \n",
       "6                0.275       0.634       1  "
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = run_all_regression('sleep')\n",
    "regression_results = pd.DataFrame(d, columns=[\"Dataset\", \"Variables\", \"Adjusted R-square\", \"Pearson Correlation\", \"F-statistic\", \"P-value\"])\n",
    "regression_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d29f2",
   "metadata": {},
   "source": [
    "### ANXIETY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "4cf45694",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Variables</th>\n",
       "      <th>Adjusted R-square</th>\n",
       "      <th>Pearson Correlation</th>\n",
       "      <th>F-statistic</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dailies</td>\n",
       "      <td>Control</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.476</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Social Media + Survey</td>\n",
       "      <td>Life Event</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.728</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Social Media + Survey</td>\n",
       "      <td>Control + Life Event</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Social Media</td>\n",
       "      <td>Life Event</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Social Media</td>\n",
       "      <td>Control + Life Event</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Survey</td>\n",
       "      <td>Life Event</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Survey</td>\n",
       "      <td>Control + Life Event</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dataset             Variables  Adjusted R-square  \\\n",
       "0                Dailies               Control              0.215   \n",
       "1  Social Media + Survey            Life Event              0.071   \n",
       "2  Social Media + Survey  Control + Life Event              0.238   \n",
       "3           Social Media            Life Event              0.086   \n",
       "4           Social Media  Control + Life Event              0.240   \n",
       "5                 Survey            Life Event              0.018   \n",
       "6                 Survey  Control + Life Event              0.323   \n",
       "\n",
       "   Pearson Correlation F-statistic P-value  \n",
       "0                0.476           -       -  \n",
       "1                0.268       0.728       1  \n",
       "2                0.474       0.893    0.99  \n",
       "3                0.365       0.764       1  \n",
       "4                0.516       0.922    0.93  \n",
       "5                0.005       0.636       1  \n",
       "6                0.376       0.925   0.761  "
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = run_all_regression('anxiety')\n",
    "regression_results = pd.DataFrame(d, columns=[\"Dataset\", \"Variables\", \"Adjusted R-square\", \"Pearson Correlation\", \"F-statistic\", \"P-value\"])\n",
    "regression_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
