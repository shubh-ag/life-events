{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10482a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: statsmodels in /home/sagarwal420/.local/lib/python3.9/site-packages (0.13.2)\n",
      "Requirement already satisfied: pandas>=0.25 in /home/sagarwal420/.local/lib/python3.9/site-packages (from statsmodels) (1.4.1)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /home/sagarwal420/.local/lib/python3.9/site-packages (from statsmodels) (0.5.2)\n",
      "Requirement already satisfied: scipy>=1.3 in /usr/local/lib/python3.9/dist-packages (from statsmodels) (1.6.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.9/dist-packages (from statsmodels) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from statsmodels) (1.20.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging>=21.3->statsmodels) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.25->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/sagarwal420/.local/lib/python3.9/site-packages (from pandas>=0.25->statsmodels) (2021.3)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from patsy>=0.5.2->statsmodels) (1.10.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: vaderSentiment in /home/sagarwal420/.local/lib/python3.9/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from vaderSentiment) (2.9.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install statsmodels\n",
    "!pip3 install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc4ee099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import date, timedelta\n",
    "import datetime\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39d1d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToTime(row, columnName):\n",
    "    return datetime.datetime.strptime(row[columnName], \"%Y-%m-%d\").date()\n",
    "\n",
    "def convertToDate(row, columnName):\n",
    "    return datetime.datetime.strptime(row[columnName], \"%Y-%m-%d %H:%M:%S\").date()\n",
    "\n",
    "def getDays(row, beginColumnName, endColumnName):\n",
    "    v = datetime.datetime.strptime(row[endColumnName], \"%Y-%m-%d\").date() - datetime.datetime.strptime(row[beginColumnName], \"%Y-%m-%d\").date()\n",
    "    return v.days\n",
    "\n",
    "def lookup_index(row, columnName, array):\n",
    "    if(row[columnName] not in array):\n",
    "        return -1\n",
    "    return array.index(row[columnName]) + 1\n",
    "\n",
    "def colour_life_events(row):\n",
    "    colours = {'personal':'lightcoral', 'health':'orange', 'work':'lightgreen', 'financial':'teal', 'weather':'blueviolet', 'societal':'navy','other':'skyblue'}\n",
    "    return colours[row['life_event_type']]\n",
    "\n",
    "def remove_rows(base_df, other_df):\n",
    "    modified_df = other_df.drop(other_df[other_df['snapshot_id'] not in base_df['snapshot_id'].values].index)\n",
    "    return modified_df\n",
    "\n",
    "def fix_signficance(row):\n",
    "    if('significance' in row['valence']):\n",
    "        return row['valence']\n",
    "    else:\n",
    "        return row['significance']\n",
    "\n",
    "def fix_valence(row):\n",
    "    if('significance' in row['significance']):\n",
    "        return row['valence']\n",
    "    else:\n",
    "        return row['significance']  \n",
    "\n",
    "def get_broad_category(row, categories, column_name):\n",
    "    if(row[column_name] in categories):\n",
    "        return categories[row[column_name]]\n",
    "    return \"UNKNOWN\"\n",
    "    \n",
    "def compute_sentiment(row):\n",
    "    post = row['Text']\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    vs = analyzer.polarity_scores(post)\n",
    "    sentiment = 0\n",
    "    if (vs[\"neu\"]>0.8):\n",
    "        sentiment = 0\n",
    "    elif (vs[\"pos\"]==vs[\"neg\"]):\n",
    "        sentiment = 0\n",
    "    elif (vs[\"pos\"]>vs[\"neg\"]):\n",
    "        sentiment = 1\n",
    "    elif (vs[\"neg\"]>vs[\"neu\"]):\n",
    "        sentiment = -1\n",
    "    return sentiment\n",
    "\n",
    "def convert_valence_to_sentiment(row):\n",
    "    valence = row['valence']\n",
    "    retVal = 0\n",
    "    if (valence == 'Neither Positive or Negative'):\n",
    "        retVal = 0\n",
    "    elif(\"Positive\" in valence):\n",
    "        retVal = 1\n",
    "    elif(\"Negative\" in valence):\n",
    "        retVal = -1\n",
    "    return retVal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcc9ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_demographics_data():\n",
    "    demographics_data = pd.read_csv('data/igtbs_demographics_complete.csv', parse_dates=True)\n",
    "    demographics_data = demographics_data[['age','gender','snapshot_id', 'shipley.vocab', 'shipley.abs', 'openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism','pos.affect','neg.affect','stai.trait']]\n",
    "    return demographics_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ae65d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_self_reported_categories():\n",
    "    df_self_reported_categories = pd.read_csv('data/Life Events Categories Mapping - Self-Reported Categories.csv')\n",
    "    return df_self_reported_categories\n",
    "\n",
    "def load_life_events_data():\n",
    "    df_life_events = pd.read_csv('data/Superimposed/LifeEvents_Curated_non_blinded.csv', parse_dates=True)\n",
    "    df_life_events = df_life_events[['snapshot_id', 'description','UpdatedBeginDate', 'UpdatedEndDate', 'date_confidence','life_event_type', 'work_perf_impact', 'significance','valence', 'ended_or_ongoing']]\n",
    "    df_life_events = df_life_events.drop(df_life_events[((df_life_events['UpdatedBeginDate'].isnull() == True) | (df_life_events['UpdatedEndDate'].isnull() == True))].index)\n",
    "    df_life_events.replace({'valence': {np.nan: 'Neither Positive or Negative'}, 'significance': {np.nan: 'Neither Positive or Negative'}, 'date_confidence': {np.nan: 'Moderate confidence'}}, inplace=True)\n",
    "\n",
    "    df_life_events['num_of_days'] = df_life_events.apply(getDays, endColumnName='UpdatedEndDate', beginColumnName='UpdatedBeginDate', axis=1)\n",
    "    df_life_events['UpdatedBeginDate_time'] = df_life_events.apply(convertToTime, columnName='UpdatedBeginDate', axis=1)\n",
    "    df_life_events['colour'] = df_life_events.apply(colour_life_events, axis=1)\n",
    "    df_life_events['fixed_signficance'] = df_life_events.apply(fix_signficance, axis = 1)\n",
    "    df_life_events['fixed_valence'] = df_life_events.apply(fix_valence, axis = 1)\n",
    "    df_life_events = df_life_events.drop(columns = ['valence', 'significance'])\n",
    "    df_life_events = df_life_events.rename(columns={\"fixed_signficance\": \"significance\", \"fixed_valence\": \"valence\"})\n",
    "    df_life_events['sentiment'] = df_life_events.apply(convert_valence_to_sentiment, axis=1)\n",
    "    df_life_events = df_life_events[['snapshot_id', 'description', 'UpdatedBeginDate', 'UpdatedEndDate', 'significance', 'sentiment']]\n",
    "    \n",
    "    le_significance = LabelEncoder()\n",
    "    le_significance.fit(df_life_events['significance'].values)\n",
    "    \n",
    "    df_life_events['significance_label'] = df_life_events.apply(lambda x: le_significance.transform([x['significance']])[0], axis=1)\n",
    "\n",
    "    df_life_events = df_life_events.drop(columns=['significance'])\n",
    "\n",
    "    return df_life_events\n",
    "\n",
    "def merge_life_event_with_reported_categories(df_life_events, df_self_reported_categories):\n",
    "    life_events_with_categories = pd.merge(df_life_events, df_self_reported_categories, how=\"inner\", left_on=\"description\", right_on=\"SR_LifeEvent\")\n",
    "    life_events_with_categories = life_events_with_categories.drop(columns=['description', 'SR_LifeEvent', 'LifeEventFinal', 'LifeEventFamily2'])\n",
    "\n",
    "    return life_events_with_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "480efef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_social_media_categories():\n",
    "    df_social_media_categories = pd.read_csv('data/Life Events Categories Mapping - Social Media Categories-2.csv')\n",
    "    return df_social_media_categories\n",
    "\n",
    "def load_social_media_data():\n",
    "    df_social_media_data = pd.read_csv('data/Superimposed/Facebook Data For Life Events-Combined - FB Data.csv')\n",
    "    df_social_media_data = df_social_media_data[['snapshot_id', 'date_enrolled', 'created_time', 'Text', 'final_life_event_category_2']]\n",
    "    df_social_media_data = df_social_media_data.replace({'PostiveMove':'PositiveMove', 'Negative Move':'NegativeMove'})\n",
    "    df_social_media_data = df_social_media_data.drop(df_social_media_data[((df_social_media_data['final_life_event_category_2'].isnull() == True))].index)\n",
    "    df_social_media_data['created_date'] = df_social_media_data.apply(convertToDate, columnName='created_time', axis=1)\n",
    "    df_social_media_data['sentiment'] = df_social_media_data.apply(compute_sentiment, axis=1)\n",
    "    df_social_media_data = df_social_media_data.drop(columns=['date_enrolled','created_time','Text'])\n",
    "    \n",
    "    return df_social_media_data\n",
    "\n",
    "def merge_social_media_data_with_categories(df_social_media_data, df_social_media_categories):\n",
    "    df_social_media_data_with_categories = pd.merge(df_social_media_data, df_social_media_categories, how=\"inner\", left_on='final_life_event_category_2', right_on='SM_LifeEvent')\n",
    "    df_social_media_data_with_categories = df_social_media_data_with_categories.drop(columns=['final_life_event_category_2','SM_LifeEvent','LifeEventFamily2','Comments','SignificanceRank'])\n",
    "    return df_social_media_data_with_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6108bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dailies_data():\n",
    "    df_dailies = pd.read_csv('data/Superimposed/dailies_scores.csv', low_memory=False)\n",
    "    df_dailies = df_dailies[['snapshot_id','day', 'alc_status', 'alc.quantity.d', 'anxiety.d', 'pos.affect.d', 'neg.affect.d','sleep.d', 'stress.d']]\n",
    "    df_dailies['day_time'] = df_dailies.apply(convertToTime, columnName='day', axis=1)\n",
    "    \n",
    "    return df_dailies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5b826b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_dailies_data(df_dailies, dependent_variable):\n",
    "    df_dailies = df_dailies.drop(df_dailies[((df_dailies[dependent_variable].isnull()))].index)\n",
    "    mean_by_snapshot_id_df = df_dailies.groupby('snapshot_id', as_index=False).mean()\n",
    "\n",
    "    return mean_by_snapshot_id_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8502a2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df_for_regression_life_events(df_life_events, df_demographics, mean_by_snapshot_id_df, df_dailies, dependent_variable):\n",
    "    mean_value_df = mean_by_snapshot_id_df[['snapshot_id', dependent_variable]]\n",
    "    merged_data = pd.merge(df_life_events, df_demographics, how=\"inner\", on=[\"snapshot_id\"])\n",
    "\n",
    "    final_input_dataset = []\n",
    "\n",
    "    # Use average values for a given snapshot id if the data for dependent variable is not available.\n",
    "    # Since the life events span over a period of time, add one row each day of life event.\n",
    "    for i in merged_data.values:\n",
    "        end_date = datetime.datetime.strptime(i[2], \"%Y-%m-%d\").date()\n",
    "        start_date = datetime.datetime.strptime(i[1], \"%Y-%m-%d\").date()\n",
    "        days = (end_date - start_date).days\n",
    "        avg_stress = list(mean_value_df[(mean_value_df['snapshot_id'] == i[0])][dependent_variable].values)\n",
    "        for j in range(days):\n",
    "            day = start_date+timedelta(days=j)\n",
    "            x = list(df_dailies[((df_dailies['snapshot_id'] == i[0]) & (df_dailies['day_time'] == day))][dependent_variable])\n",
    "\n",
    "            stres = 0\n",
    "            actual_stress = 0\n",
    "            if(len(x) != 0):\n",
    "                stres = x[0]\n",
    "                actual_stress = stres\n",
    "            else:\n",
    "                stres = avg_stress[0]\n",
    "            s_d = []\n",
    "            s_d.extend(i)\n",
    "            s_d.append(actual_stress)\n",
    "            s_d.append(stres)\n",
    "            s_d.append(day)\n",
    "            final_input_dataset.append(s_d)\n",
    "                \n",
    "    final_input_dataset = pd.DataFrame(final_input_dataset, columns=[\n",
    "        'snapshot_id', 'UpdatedBeginDate', 'UpdatedEndDate', 'sentiment','significance_label',  'LifeEventFamily', 'Anticipation', 'Intimacy',\n",
    "       'Scope',        'age','gender', 'shipley.vocab', 'shipley.abs', 'openness', 'conscientiousness',\n",
    "           'extraversion', 'agreeableness', 'neuroticism', 'pos.affect',\n",
    "           'neg.affect', 'stai.trait', 'stress.d', 'stress.average', 'exact_day'])     \n",
    "\n",
    "    X_input = final_input_dataset.drop(columns=['snapshot_id', 'UpdatedBeginDate', 'UpdatedEndDate', 'exact_day', 'stress.d'])\n",
    "    X_input = X_input.dropna()\n",
    "    X_input = X_input.rename(columns={\"stress.average\":\"stress\", \"shipley.vocab\": \"shipley_vocab\", \"shipley.abs\":\"shipley_abs\", \"pos.affect\":\"pos_affect\", \"neg.affect\":\"neg_affect\", \"stai.trait\":\"stai_trait\"})\n",
    "\n",
    "    return X_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf61b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_df_for_regression_social_media(df_social_media, df_demographics, mean_by_snapshot_id_df, df_dailies, dependent_variable):\n",
    "    mean_value_df = mean_by_snapshot_id_df[['snapshot_id', dependent_variable]]\n",
    "    merged_data = pd.merge(df_social_media, df_demographics, how=\"inner\", on=[\"snapshot_id\"])\n",
    "\n",
    "    final_input_dataset = []\n",
    "\n",
    "    #Use average values for a given snapshot id if the data for dependent variable is not available.\n",
    "    for i in merged_data.values:\n",
    "        day = i[2]\n",
    "        avg_stress = list(mean_value_df[(mean_value_df['snapshot_id'] == i[0])][dependent_variable].values)\n",
    "\n",
    "        x = list(df_dailies[((df_dailies['snapshot_id'] == i[0]) & (df_dailies['day_time'] == day))][dependent_variable])\n",
    "        stres = 0\n",
    "        actual_stress = 0\n",
    "        if(len(x) != 0):\n",
    "            stres = x[0]\n",
    "            actual_stress = stres\n",
    "        else:\n",
    "            stres = avg_stress[0]\n",
    "        s_d = []\n",
    "        s_d.extend(i)\n",
    "        s_d.append(actual_stress)\n",
    "        s_d.append(stres)\n",
    "        s_d.append(day)\n",
    "        final_input_dataset.append(s_d)\n",
    "        \n",
    "    final_input_dataset = pd.DataFrame(final_input_dataset, columns=[\n",
    "        'snapshot_id', 'created_date','sentiment', 'LifeEventFamily',\n",
    "       'Anticipation', 'Intimacy', 'Scope', 'age','gender', 'shipley.vocab', 'shipley.abs', 'openness', 'conscientiousness',\n",
    "           'extraversion', 'agreeableness', 'neuroticism', 'pos.affect',\n",
    "           'neg.affect', 'stai.trait', 'stress.d', 'stress.average', 'exact_day'])     \n",
    "    \n",
    "    X_input = final_input_dataset.drop(columns=['snapshot_id', 'created_date', 'exact_day', 'stress.d'])\n",
    "    X_input = X_input.dropna()\n",
    "    X_input = X_input.rename(columns={\"stress.average\":\"stress\", \"shipley.vocab\": \"shipley_vocab\", \"shipley.abs\":\"shipley_abs\", \"pos.affect\":\"pos_affect\", \"neg.affect\":\"neg_affect\", \"stai.trait\":\"stai_trait\"})\n",
    "    \n",
    "    return X_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "016d1ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_life_events(df_life_events, df_demographics, mean_by_snapshot_id_df, df_dailies, dependent_variable):\n",
    "    X_input = build_df_for_regression_life_events(df_life_events, df_demographics, mean_by_snapshot_id_df, df_dailies, dependent_variable)\n",
    "    print(\"Total Rows: \", len(X_input.values))\n",
    "\n",
    "    mod = smf.ols(formula='stress~age + shipley_vocab + shipley_abs + openness + conscientiousness + extraversion + agreeableness + neuroticism + pos_affect + neg_affect + stai_trait + sentiment + Anticipation + Intimacy + Scope + LifeEventFamily + gender + significance_label', data=X_input)\n",
    "    res = mod.fit()\n",
    "    return res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7ec869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_social_media_events(df_social_media, df_demographics, mean_by_snapshot_id_df, df_dailies, dependent_variable):\n",
    "    X_input = build_df_for_regression_social_media(df_social_media, df_demographics, mean_by_snapshot_id_df, df_dailies, dependent_variable)\n",
    "    print(\"Total Rows: \", len(X_input.values))\n",
    "\n",
    "    mod = smf.ols(formula='stress~age + shipley_vocab + shipley_abs + openness + conscientiousness + extraversion + agreeableness + neuroticism + pos_affect + neg_affect + stai_trait + sentiment + Anticipation + Intimacy + Scope + LifeEventFamily + gender', data=X_input)\n",
    "    res = mod.fit()\n",
    "    return res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e2eda24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_combined_survey_social_media(df_life_events, df_social_media, df_demographics, mean_by_snapshot_id_df, df_dailies, dependent_variable):\n",
    "    df_survey = build_df_for_regression_life_events(df_life_events, df_demographics, mean_by_snapshot_id_df, df_dailies, dependent_variable)\n",
    "    df_social_media = build_df_for_regression_social_media(df_social_media, df_demographics, mean_by_snapshot_id_df, df_dailies, dependent_variable)\n",
    "    \n",
    "    df_survey['Data_Type'] = 'Survey'\n",
    "    df_survey = df_survey[['sentiment', 'LifeEventFamily', 'Anticipation', 'Intimacy', 'Scope',\n",
    "                           'age', 'gender', 'shipley_vocab', 'shipley_abs',\n",
    "                           'openness', 'conscientiousness', 'extraversion', 'agreeableness',\n",
    "                           'neuroticism', 'pos_affect', 'neg_affect', 'stai_trait', 'stress', 'Data_Type']]\n",
    "    df_social_media['Data_Type'] = 'Social Media'\n",
    "    df_social_media = df_social_media[['sentiment', 'LifeEventFamily', 'Anticipation', 'Intimacy', 'Scope',\n",
    "                           'age', 'gender', 'shipley_vocab', 'shipley_abs',\n",
    "                           'openness', 'conscientiousness', 'extraversion', 'agreeableness',\n",
    "                           'neuroticism', 'pos_affect', 'neg_affect', 'stai_trait', 'stress', 'Data_Type']]\n",
    "    \n",
    "    X_input = pd.concat([df_survey, df_social_media])\n",
    "\n",
    "    print(\"Total Rows: \", len(X_input.values))\n",
    "    mod = smf.ols(formula='stress~age + shipley_vocab + shipley_abs + openness + conscientiousness + extraversion + agreeableness + neuroticism + pos_affect + neg_affect + stai_trait + sentiment + Anticipation + Intimacy + Scope + LifeEventFamily + gender + Data_Type', data=X_input)\n",
    "    res = mod.fit()\n",
    "    return res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5378ee72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def linear_regression(dependent_variable):\n",
    "    #Load all the data\n",
    "    df_dailies = load_dailies_data()\n",
    "    mean_by_snapshot_id_df = calculate_mean_dailies_data(df_dailies, dependent_variable)\n",
    "    \n",
    "    df_social_media = merge_social_media_data_with_categories(load_social_media_data(), load_social_media_categories())\n",
    "    \n",
    "    df_life_events = load_life_events_data()\n",
    "    df_self_report_categories = load_self_reported_categories()\n",
    "    df_life_events_with_categories = merge_life_event_with_reported_categories(df_life_events, df_self_report_categories)\n",
    "    \n",
    "    df_demographics = load_demographics_data()\n",
    "        \n",
    "    #Run regression\n",
    "    print(\"Regression based on life events!\")\n",
    "    print(regression_life_events(df_life_events_with_categories, df_demographics, mean_by_snapshot_id_df, df_dailies, dependent_variable))\n",
    "    print()\n",
    "    print(\"Regression using Social Media Events!\")\n",
    "    print(regression_social_media_events(df_social_media, df_demographics, mean_by_snapshot_id_df, df_dailies, dependent_variable))\n",
    "    print()\n",
    "    print(\"Regression using combined survey and social media data!\")\n",
    "    print(regression_combined_survey_social_media(df_life_events_with_categories, df_social_media, df_demographics, mean_by_snapshot_id_df, df_dailies, dependent_variable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56aeac92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression using combined survey and social media data!\n",
      "Total Rows:  19067\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 stress   R-squared:                       0.222\n",
      "Model:                            OLS   Adj. R-squared:                  0.221\n",
      "Method:                 Least Squares   F-statistic:                     246.9\n",
      "Date:                Tue, 10 May 2022   Prob (F-statistic):               0.00\n",
      "Time:                        13:42:10   Log-Likelihood:                -13799.\n",
      "No. Observations:               19067   AIC:                         2.764e+04\n",
      "Df Residuals:                   19044   BIC:                         2.783e+04\n",
      "Df Model:                          22                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================================\n",
      "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Intercept                         0.6954      0.081      8.615      0.000       0.537       0.854\n",
      "Anticipation[T.Unanticipated]    -0.0268      0.010     -2.763      0.006      -0.046      -0.008\n",
      "LifeEventFamily[T.Health]         0.3358      0.027     12.302      0.000       0.282       0.389\n",
      "LifeEventFamily[T.Local]          0.4601      0.030     15.338      0.000       0.401       0.519\n",
      "LifeEventFamily[T.Personal]       0.3415      0.023     14.538      0.000       0.295       0.388\n",
      "LifeEventFamily[T.School]         0.5234      0.031     16.952      0.000       0.463       0.584\n",
      "LifeEventFamily[T.Work]           0.3810      0.024     15.562      0.000       0.333       0.429\n",
      "gender[T.Male]                   -0.0694      0.009     -7.705      0.000      -0.087      -0.052\n",
      "Data_Type[T.Survey]               0.1654      0.013     12.468      0.000       0.139       0.191\n",
      "age                              -0.0034      0.000     -7.461      0.000      -0.004      -0.003\n",
      "shipley_vocab                    -0.0010      0.001     -0.963      0.336      -0.003       0.001\n",
      "shipley_abs                      -0.0265      0.002    -16.735      0.000      -0.030      -0.023\n",
      "openness                         -0.0329      0.007     -4.892      0.000      -0.046      -0.020\n",
      "conscientiousness                 0.0317      0.007      4.612      0.000       0.018       0.045\n",
      "extraversion                      0.1279      0.007     18.991      0.000       0.115       0.141\n",
      "agreeableness                     0.1153      0.008     14.704      0.000       0.100       0.131\n",
      "neuroticism                       0.0442      0.008      5.735      0.000       0.029       0.059\n",
      "pos_affect                       -0.0072      0.001     -7.140      0.000      -0.009      -0.005\n",
      "neg_affect                        0.0377      0.001     30.108      0.000       0.035       0.040\n",
      "stai_trait                        0.0060      0.001      7.288      0.000       0.004       0.008\n",
      "sentiment                        -0.0602      0.005    -12.849      0.000      -0.069      -0.051\n",
      "Intimacy                         -0.0205      0.009     -2.162      0.031      -0.039      -0.002\n",
      "Scope                             0.0133      0.011      1.181      0.238      -0.009       0.035\n",
      "==============================================================================\n",
      "Omnibus:                      532.042   Durbin-Watson:                   0.451\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1030.582\n",
      "Skew:                           0.204   Prob(JB):                    1.63e-224\n",
      "Kurtosis:                       4.064   Cond. No.                     1.76e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.76e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "linear_regression('stress.d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f46a368",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression using combined survey and social media data!\n",
      "Total Rows:  18145\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 stress   R-squared:                       0.172\n",
      "Model:                            OLS   Adj. R-squared:                  0.171\n",
      "Method:                 Least Squares   F-statistic:                     171.7\n",
      "Date:                Tue, 10 May 2022   Prob (F-statistic):               0.00\n",
      "Time:                        13:43:38   Log-Likelihood:                -16248.\n",
      "No. Observations:               18145   AIC:                         3.254e+04\n",
      "Df Residuals:                   18122   BIC:                         3.272e+04\n",
      "Df Model:                          22                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================================\n",
      "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Intercept                         6.6391      0.098     68.051      0.000       6.448       6.830\n",
      "Anticipation[T.Unanticipated]    -0.1385      0.012    -11.703      0.000      -0.162      -0.115\n",
      "LifeEventFamily[T.Health]         0.0304      0.033      0.920      0.358      -0.034       0.095\n",
      "LifeEventFamily[T.Local]          0.0541      0.036      1.485      0.138      -0.017       0.125\n",
      "LifeEventFamily[T.Personal]       0.0518      0.029      1.814      0.070      -0.004       0.108\n",
      "LifeEventFamily[T.School]         0.1957      0.037      5.220      0.000       0.122       0.269\n",
      "LifeEventFamily[T.Work]           0.1285      0.030      4.312      0.000       0.070       0.187\n",
      "gender[T.Male]                   -0.0805      0.011     -7.373      0.000      -0.102      -0.059\n",
      "Data_Type[T.Survey]               0.0736      0.016      4.650      0.000       0.043       0.105\n",
      "age                               0.0019      0.001      3.384      0.001       0.001       0.003\n",
      "shipley_vocab                     0.0077      0.001      5.929      0.000       0.005       0.010\n",
      "shipley_abs                       0.0350      0.002     18.250      0.000       0.031       0.039\n",
      "openness                          0.0341      0.008      4.170      0.000       0.018       0.050\n",
      "conscientiousness                -0.0438      0.008     -5.229      0.000      -0.060      -0.027\n",
      "extraversion                     -0.1316      0.008    -16.070      0.000      -0.148      -0.116\n",
      "agreeableness                     0.0542      0.010      5.702      0.000       0.036       0.073\n",
      "neuroticism                       0.3111      0.009     33.232      0.000       0.293       0.329\n",
      "pos_affect                       -0.0056      0.001     -4.586      0.000      -0.008      -0.003\n",
      "neg_affect                       -0.0134      0.002     -8.813      0.000      -0.016      -0.010\n",
      "stai_trait                       -0.0169      0.001    -16.917      0.000      -0.019      -0.015\n",
      "sentiment                        -0.0634      0.006    -11.078      0.000      -0.075      -0.052\n",
      "Intimacy                          0.1375      0.012     11.950      0.000       0.115       0.160\n",
      "Scope                            -0.0849      0.014     -6.186      0.000      -0.112      -0.058\n",
      "==============================================================================\n",
      "Omnibus:                     4647.242   Durbin-Watson:                   0.484\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            60494.802\n",
      "Skew:                          -0.865   Prob(JB):                         0.00\n",
      "Kurtosis:                      11.776   Cond. No.                     1.75e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.75e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "linear_regression('sleep.d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d013632",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression using combined survey and social media data!\n",
      "Total Rows:  19066\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 stress   R-squared:                       0.308\n",
      "Model:                            OLS   Adj. R-squared:                  0.308\n",
      "Method:                 Least Squares   F-statistic:                     385.8\n",
      "Date:                Tue, 10 May 2022   Prob (F-statistic):               0.00\n",
      "Time:                        13:44:44   Log-Likelihood:                -11783.\n",
      "No. Observations:               19066   AIC:                         2.361e+04\n",
      "Df Residuals:                   19043   BIC:                         2.379e+04\n",
      "Df Model:                          22                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================================\n",
      "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Intercept                         1.3060      0.073     17.985      0.000       1.164       1.448\n",
      "Anticipation[T.Unanticipated]    -0.0005      0.009     -0.063      0.950      -0.018       0.017\n",
      "LifeEventFamily[T.Health]        -0.0060      0.025     -0.244      0.807      -0.054       0.042\n",
      "LifeEventFamily[T.Local]          0.1237      0.027      4.585      0.000       0.071       0.177\n",
      "LifeEventFamily[T.Personal]       0.0651      0.021      3.078      0.002       0.024       0.106\n",
      "LifeEventFamily[T.School]         0.0354      0.028      1.274      0.203      -0.019       0.090\n",
      "LifeEventFamily[T.Work]           0.0292      0.022      1.325      0.185      -0.014       0.072\n",
      "gender[T.Male]                   -0.0504      0.008     -6.219      0.000      -0.066      -0.035\n",
      "Data_Type[T.Survey]               0.1771      0.012     14.839      0.000       0.154       0.200\n",
      "age                              -0.0065      0.000    -15.777      0.000      -0.007      -0.006\n",
      "shipley_vocab                    -0.0066      0.001     -6.814      0.000      -0.008      -0.005\n",
      "shipley_abs                      -0.0354      0.001    -24.777      0.000      -0.038      -0.033\n",
      "openness                         -0.0271      0.006     -4.474      0.000      -0.039      -0.015\n",
      "conscientiousness                -0.0097      0.006     -1.574      0.116      -0.022       0.002\n",
      "extraversion                      0.1701      0.006     28.080      0.000       0.158       0.182\n",
      "agreeableness                     0.1018      0.007     14.420      0.000       0.088       0.116\n",
      "neuroticism                       0.0496      0.007      7.159      0.000       0.036       0.063\n",
      "pos_affect                       -0.0158      0.001    -17.382      0.000      -0.018      -0.014\n",
      "neg_affect                        0.0375      0.001     33.337      0.000       0.035       0.040\n",
      "stai_trait                        0.0056      0.001      7.559      0.000       0.004       0.007\n",
      "sentiment                        -0.0207      0.004     -4.915      0.000      -0.029      -0.012\n",
      "Intimacy                         -0.0886      0.009    -10.377      0.000      -0.105      -0.072\n",
      "Scope                             0.1117      0.010     11.016      0.000       0.092       0.132\n",
      "==============================================================================\n",
      "Omnibus:                     2861.968   Durbin-Watson:                   0.428\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7224.016\n",
      "Skew:                           0.845   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.498   Cond. No.                     1.76e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.76e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "linear_regression('anxiety.d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
